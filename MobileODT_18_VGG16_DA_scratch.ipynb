{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intel MobileODT Kaggle competition\n",
    "\n",
    "https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:01:00.0)\n",
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theano version: 0.9.0\n",
      "Keras version: 2.0.3\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from __future__ import print_function, division\n",
    "from importlib import reload \n",
    "import utils_p3; reload(utils_p3)\n",
    "from utils_p3 import *\n",
    "%matplotlib inline\n",
    "from IPython.display import FileLink\n",
    "import tensorflow as tf\n",
    "import six\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "from PIL import ImageFile\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "#print(\"TensorFlow version: %s\" % tf.__version__)\n",
    "print(\"Theano version: %s\" % theano.__version__)\n",
    "print(\"Keras version: %s\" % keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_first'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME_DIR = os.getcwd()\n",
    "#path = \"data/imgs/\"\n",
    "path = \"data/testing/\"\n",
    "#path = \"data/testing/sample/\"\n",
    "train_valid_fraction = 0.75\n",
    "image_shape = (224,224)\n",
    "patience = 3\n",
    "batch_size = 64\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "keras.backend.image_data_format() #verify image_data_format for theano vs TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/eric/SSD500/fastai/deeplearning1/nbs/MobileODT'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/eric/SSD500/fastai/deeplearning1/nbs/MobileODT'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5048 images belonging to 3 classes.\n",
      "Found 1683 images belonging to 3 classes.\n",
      "Found 4018 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', batch_size=batch_size, shuffle=False)\n",
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)\n",
    "test_batches = get_batches(path+'test', batch_size=batch_size*2, shuffle=False)\n",
    "steps_per_epoch = int(np.ceil(batches.samples/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.samples/(batch_size*2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5048 images belonging to 3 classes.\n",
      "Found 1683 images belonging to 3 classes.\n",
      "Found 4018 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Imagenet conv features with VGG16\n",
    "from Statefarm_original notebook\n",
    "\n",
    "Since we have so little data, and it is similar to imagenet images (full color photos), using pre-trained VGG weights is likely to be helpful - in fact it seems likely that we won't need to fine-tune the convolutional layer weights much, if at all.\n",
    "\n",
    "So we can pre-compute the output of the last convolutional layer, as we did in lesson 3 when we experimented with dropout. (However this means that we can't use full data augmentation, since we can't pre-compute something that changes every image.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import our class\n",
    "import vgg16_p3; reload(vgg16_p3)\n",
    "from vgg16_p3 import Vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: pre-compute the output of the last convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab VGG16 and find the last convolutional layer\n",
    "vgg = Vgg16()\n",
    "model=vgg.model\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a new model that includes everything up to that last convolutional layer\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the outputs of that model by calculating the activations of that last convolutional layer\n",
    "conv_feat = conv_model.predict_generator(batches, int(np.ceil(batches.samples/batch_size)), workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As this takes time, save it to load it in the future\n",
    "save_array(path+'results/conv_feat.dat', conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_val_feat = conv_model.predict_generator(val_batches, int(np.ceil(val_batches.samples/(batch_size*2))), workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/conv_val_feat.dat', conv_val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = conv_model.predict_generator(test_batches, int(np.ceil(test_batches.samples/(batch_size*2))), workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/conv_test_feat.dat', conv_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Augmentation: at 1:15:55 in L4 video, we can see Jeremy had a cell for gen_t,\n",
    "# then computed a da_conv_feat with nb_sample*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can look at the original model and find the last convo layer \"conv2d_13\" with output shape (none, 512, 14, 14)\n",
    "# and compare it with the shape of of our new model's output.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It's the same than \"conv2d_13\" !\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feat = load_array(path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path+'results/conv_val_feat.dat')\n",
    "conv_test_feat = load_array(path+'results/conv_test_feat.dat')\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build new model on top, with dense layers\n",
    "Since we've pre-computed the output of the last convolutional layer, we need to create a network that takes that as input, and predicts our 10 classes. Let's try using a simplified version of VGG's dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we make 'p' a parameter to try different Dropout amounts\n",
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(3, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=25, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.8\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=50, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 3: Pre-computed data augmentation by making 5 augmented copies of training set\n",
    "\n",
    "We'll use our usual data augmentation parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# potential DA: warning uses HUGE amount of RAM and takes like 90 mins for a simple batches.samples*2, check forum.\n",
    "# http://forums.fast.ai/t/state-farm-full-how-not-to-run-out-of-memory-with-vgg-da-batches-samples-5/3469/2\n",
    "# maybe reduce batch_size below to 1 ? YES !!!\n",
    "gen_t = image.ImageDataGenerator(rotation_range=8, height_shift_range=0.025,\n",
    "                                shear_range=0.05, channel_shift_range=10, width_shift_range=0.1)\n",
    "da_batches = get_batches(path+'train', gen_t, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = conv_model.predict_generator(da_batches, int(np.ceil(da_batches.samples*5)), workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/da_5_conv_feat.dat', da_conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = load_array(path+'results/da_5_conv_feat.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's include the real training data as well in its non-augmented form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat = load_array(path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path+'results/conv_val_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat_update = np.concatenate([da_conv_feat, conv_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/da_5_conv_feat_update.dat', da_conv_feat_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat_update = load_array(path+'results/da_5_conv_feat_update.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since we've now got a dataset 6x bigger than before, we'll need to copy our labels 6 times too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_trn_labels = np.concatenate([trn_labels]*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/da_trn_labels.dat', da_trn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_trn_labels = load_array(path+'results/da_trn_labels.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Based on some experiments the previous model works well, maybe with bigger dense layers like 512 later ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we make 'p' a parameter to try different Dropout amounts and we take out flatten here\n",
    "def get_bn_da_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(3, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_da_model = Sequential(get_bn_da_layers(p))\n",
    "bn_da_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/1\n",
      "30288/30288 [==============================] - 34s - loss: 1.3651 - acc: 0.6119 - val_loss: 1.6018 - val_acc: 0.5663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f807e848f60>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=batch_size, epochs=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/50\n",
      "30288/30288 [==============================] - 31s - loss: 0.6745 - acc: 0.7694 - val_loss: 1.7393 - val_acc: 0.5977\n",
      "Epoch 2/50\n",
      "30288/30288 [==============================] - 17s - loss: 0.5183 - acc: 0.8312 - val_loss: 1.8474 - val_acc: 0.6031\n",
      "Epoch 3/50\n",
      "30288/30288 [==============================] - 15s - loss: 0.4609 - acc: 0.8556 - val_loss: 2.0051 - val_acc: 0.6173\n",
      "Epoch 4/50\n",
      "30288/30288 [==============================] - 15s - loss: 0.3789 - acc: 0.8814 - val_loss: 1.7808 - val_acc: 0.6227\n",
      "Epoch 5/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.3336 - acc: 0.8961 - val_loss: 2.1367 - val_acc: 0.5995\n",
      "Epoch 6/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.2922 - acc: 0.9072 - val_loss: 2.0435 - val_acc: 0.6191\n",
      "Epoch 7/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.2819 - acc: 0.9145 - val_loss: 1.9085 - val_acc: 0.6370\n",
      "Epoch 8/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.2527 - acc: 0.9220 - val_loss: 2.0581 - val_acc: 0.6257\n",
      "Epoch 9/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.2406 - acc: 0.9260 - val_loss: 2.2447 - val_acc: 0.6316\n",
      "Epoch 10/50\n",
      "30288/30288 [==============================] - 15s - loss: 0.2174 - acc: 0.9323 - val_loss: 2.2436 - val_acc: 0.6185\n",
      "Epoch 11/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.2201 - acc: 0.9345 - val_loss: 2.2784 - val_acc: 0.6423\n",
      "Epoch 12/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.2020 - acc: 0.9405 - val_loss: 2.2298 - val_acc: 0.6292\n",
      "Epoch 13/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1846 - acc: 0.9439 - val_loss: 2.2479 - val_acc: 0.6209\n",
      "Epoch 14/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1720 - acc: 0.9487 - val_loss: 2.3018 - val_acc: 0.6310\n",
      "Epoch 15/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1661 - acc: 0.9526 - val_loss: 2.3346 - val_acc: 0.6298\n",
      "Epoch 16/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1573 - acc: 0.9538 - val_loss: 2.3699 - val_acc: 0.6328.95\n",
      "Epoch 17/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1607 - acc: 0.9523 - val_loss: 2.2143 - val_acc: 0.6417\n",
      "Epoch 18/50\n",
      "30288/30288 [==============================] - 15s - loss: 0.1490 - acc: 0.9564 - val_loss: 2.4637 - val_acc: 0.6334\n",
      "Epoch 19/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1518 - acc: 0.9559 - val_loss: 2.4291 - val_acc: 0.6280\n",
      "Epoch 20/50\n",
      "30288/30288 [==============================] - 15s - loss: 0.1526 - acc: 0.9570 - val_loss: 2.2992 - val_acc: 0.6494\n",
      "Epoch 21/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1378 - acc: 0.9603 - val_loss: 2.2439 - val_acc: 0.6435\n",
      "Epoch 22/50\n",
      "30288/30288 [==============================] - 15s - loss: 0.1219 - acc: 0.9650 - val_loss: 2.4701 - val_acc: 0.6328\n",
      "Epoch 23/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1266 - acc: 0.9648 - val_loss: 2.3454 - val_acc: 0.6316\n",
      "Epoch 24/50\n",
      "30288/30288 [==============================] - 15s - loss: 0.1168 - acc: 0.9675 - val_loss: 2.6776 - val_acc: 0.6381\n",
      "Epoch 25/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1225 - acc: 0.9666 - val_loss: 2.4386 - val_acc: 0.6417\n",
      "Epoch 26/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1123 - acc: 0.9682 - val_loss: 2.3694 - val_acc: 0.6364\n",
      "Epoch 27/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1095 - acc: 0.9683 - val_loss: 2.3032 - val_acc: 0.6459\n",
      "Epoch 28/50\n",
      "30288/30288 [==============================] - 15s - loss: 0.1105 - acc: 0.9695 - val_loss: 2.4381 - val_acc: 0.6477\n",
      "Epoch 29/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1051 - acc: 0.9705 - val_loss: 2.4199 - val_acc: 0.6477\n",
      "Epoch 30/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1030 - acc: 0.9722 - val_loss: 2.3952 - val_acc: 0.6417\n",
      "Epoch 31/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.1005 - acc: 0.9718 - val_loss: 2.5038 - val_acc: 0.6393\n",
      "Epoch 32/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0991 - acc: 0.9721 - val_loss: 2.4642 - val_acc: 0.6417\n",
      "Epoch 33/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0986 - acc: 0.9724 - val_loss: 2.4457 - val_acc: 0.6518\n",
      "Epoch 34/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0962 - acc: 0.9725 - val_loss: 2.5992 - val_acc: 0.6381\n",
      "Epoch 35/50\n",
      "30288/30288 [==============================] - 15s - loss: 0.0915 - acc: 0.9757 - val_loss: 2.5795 - val_acc: 0.6381\n",
      "Epoch 36/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0914 - acc: 0.9750 - val_loss: 2.3842 - val_acc: 0.6566\n",
      "Epoch 37/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0951 - acc: 0.9759 - val_loss: 2.4979 - val_acc: 0.6500\n",
      "Epoch 38/50\n",
      "30288/30288 [==============================] - 15s - loss: 0.0956 - acc: 0.9729 - val_loss: 2.3577 - val_acc: 0.6459\n",
      "Epoch 39/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0861 - acc: 0.9758 - val_loss: 2.5954 - val_acc: 0.6399\n",
      "Epoch 40/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0907 - acc: 0.9760 - val_loss: 2.5707 - val_acc: 0.6506\n",
      "Epoch 41/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0842 - acc: 0.9777 - val_loss: 2.3999 - val_acc: 0.6459\n",
      "Epoch 42/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0834 - acc: 0.9779 - val_loss: 2.3976 - val_acc: 0.6393\n",
      "Epoch 43/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0913 - acc: 0.9760 - val_loss: 2.4742 - val_acc: 0.6471\n",
      "Epoch 44/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0682 - acc: 0.9804 - val_loss: 2.5538 - val_acc: 0.6376\n",
      "Epoch 45/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0733 - acc: 0.9804 - val_loss: 2.4363 - val_acc: 0.6471\n",
      "Epoch 46/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0743 - acc: 0.9803 - val_loss: 2.5004 - val_acc: 0.6482\n",
      "Epoch 47/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0722 - acc: 0.9799 - val_loss: 2.4419 - val_acc: 0.6435\n",
      "Epoch 48/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0692 - acc: 0.9808 - val_loss: 2.4984 - val_acc: 0.6494\n",
      "Epoch 49/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0664 - acc: 0.9821 - val_loss: 2.4038 - val_acc: 0.6554\n",
      "Epoch 50/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.0733 - acc: 0.9794 - val_loss: 2.4433 - val_acc: 0.6482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f807e83f1d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=batch_size, epochs=50, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's save those weights.\n",
    "bn_da_model.save_weights(path+'models/bn_da5_conv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's load those weights.\n",
    "bn_da_model.load_weights(path+'models/bn_da5_conv2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some test not saved with different learning rates or optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_da_model.compile(RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/25\n",
      "30288/30288 [==============================] - 12s - loss: 0.2520 - acc: 0.9455 - val_loss: 2.6079 - val_acc: 0.6423\n",
      "Epoch 2/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.2131 - acc: 0.9491 - val_loss: 2.4361 - val_acc: 0.6376\n",
      "Epoch 3/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1904 - acc: 0.9513 - val_loss: 2.3996 - val_acc: 0.6393\n",
      "Epoch 4/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1887 - acc: 0.9515 - val_loss: 2.2177 - val_acc: 0.6387\n",
      "Epoch 5/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1765 - acc: 0.9507 - val_loss: 2.1010 - val_acc: 0.6441\n",
      "Epoch 6/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1566 - acc: 0.9559 - val_loss: 1.9740 - val_acc: 0.6387\n",
      "Epoch 7/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1462 - acc: 0.9558 - val_loss: 2.0105 - val_acc: 0.6453\n",
      "Epoch 8/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1371 - acc: 0.9578 - val_loss: 1.9590 - val_acc: 0.6447\n",
      "Epoch 9/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1372 - acc: 0.9582 - val_loss: 1.8838 - val_acc: 0.6429\n",
      "Epoch 10/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1245 - acc: 0.9599 - val_loss: 1.9807 - val_acc: 0.6465\n",
      "Epoch 11/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1207 - acc: 0.9621 - val_loss: 1.9875 - val_acc: 0.6429\n",
      "Epoch 12/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1256 - acc: 0.9608 - val_loss: 1.9818 - val_acc: 0.6364\n",
      "Epoch 13/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1135 - acc: 0.9627 - val_loss: 1.9085 - val_acc: 0.6453\n",
      "Epoch 14/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1100 - acc: 0.9646 - val_loss: 1.8316 - val_acc: 0.6423\n",
      "Epoch 15/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1004 - acc: 0.9668 - val_loss: 1.9765 - val_acc: 0.6310\n",
      "Epoch 16/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1067 - acc: 0.9668 - val_loss: 1.8351 - val_acc: 0.6447\n",
      "Epoch 17/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1107 - acc: 0.9635 - val_loss: 1.8068 - val_acc: 0.6411\n",
      "Epoch 18/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1039 - acc: 0.9663 - val_loss: 1.8866 - val_acc: 0.6364\n",
      "Epoch 19/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.1036 - acc: 0.9673 - val_loss: 1.8265 - val_acc: 0.6459\n",
      "Epoch 20/25\n",
      "30288/30288 [==============================] - 12s - loss: 0.1015 - acc: 0.9666 - val_loss: 1.8413 - val_acc: 0.6393\n",
      "Epoch 21/25\n",
      "30288/30288 [==============================] - 12s - loss: 0.1016 - acc: 0.9680 - val_loss: 1.7903 - val_acc: 0.6429\n",
      "Epoch 22/25\n",
      "30288/30288 [==============================] - 12s - loss: 0.0966 - acc: 0.9676 - val_loss: 1.9186 - val_acc: 0.6459\n",
      "Epoch 23/25\n",
      "30288/30288 [==============================] - 12s - loss: 0.0969 - acc: 0.9690 - val_loss: 1.8737 - val_acc: 0.6405\n",
      "Epoch 24/25\n",
      "30288/30288 [==============================] - 12s - loss: 0.0988 - acc: 0.9675 - val_loss: 1.8477 - val_acc: 0.6393\n",
      "Epoch 25/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0910 - acc: 0.9698 - val_loss: 1.8149 - val_acc: 0.6298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f801cb94940>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=batch_size, epochs=25, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/25\n",
      "30288/30288 [==============================] - 14s - loss: 0.0889 - acc: 0.9705 - val_loss: 1.7762 - val_acc: 0.6465\n",
      "Epoch 2/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0852 - acc: 0.9727 - val_loss: 1.7887 - val_acc: 0.6471\n",
      "Epoch 3/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0898 - acc: 0.9702 - val_loss: 1.7650 - val_acc: 0.6488\n",
      "Epoch 4/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0915 - acc: 0.9704 - val_loss: 1.7723 - val_acc: 0.6482\n",
      "Epoch 5/25\n",
      "30288/30288 [==============================] - 12s - loss: 0.0854 - acc: 0.9714 - val_loss: 1.7676 - val_acc: 0.6471\n",
      "Epoch 6/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0848 - acc: 0.9719 - val_loss: 1.7625 - val_acc: 0.6477\n",
      "Epoch 7/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0901 - acc: 0.9705 - val_loss: 1.7565 - val_acc: 0.6465\n",
      "Epoch 8/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0882 - acc: 0.9714 - val_loss: 1.7489 - val_acc: 0.6471\n",
      "Epoch 9/25\n",
      "30288/30288 [==============================] - 17s - loss: 0.0901 - acc: 0.9704 - val_loss: 1.7462 - val_acc: 0.6459\n",
      "Epoch 10/25\n",
      "30288/30288 [==============================] - 14s - loss: 0.0861 - acc: 0.9712 - val_loss: 1.7434 - val_acc: 0.6494\n",
      "Epoch 11/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0916 - acc: 0.9699 - val_loss: 1.7411 - val_acc: 0.6477\n",
      "Epoch 12/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0881 - acc: 0.9717 - val_loss: 1.7458 - val_acc: 0.6482\n",
      "Epoch 13/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0886 - acc: 0.9703 - val_loss: 1.7461 - val_acc: 0.6488\n",
      "Epoch 14/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0874 - acc: 0.9708 - val_loss: 1.7322 - val_acc: 0.6429\n",
      "Epoch 15/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0883 - acc: 0.9720 - val_loss: 1.7507 - val_acc: 0.6488\n",
      "Epoch 16/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0880 - acc: 0.9704 - val_loss: 1.7398 - val_acc: 0.6488\n",
      "Epoch 17/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0832 - acc: 0.9730 - val_loss: 1.7363 - val_acc: 0.6471\n",
      "Epoch 18/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0879 - acc: 0.9712 - val_loss: 1.7457 - val_acc: 0.6459\n",
      "Epoch 19/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0856 - acc: 0.9721 - val_loss: 1.7220 - val_acc: 0.6471\n",
      "Epoch 20/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0888 - acc: 0.9713 - val_loss: 1.7291 - val_acc: 0.6471\n",
      "Epoch 21/25\n",
      "30288/30288 [==============================] - 14s - loss: 0.0859 - acc: 0.9711 - val_loss: 1.7447 - val_acc: 0.6494\n",
      "Epoch 22/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0892 - acc: 0.9701 - val_loss: 1.7346 - val_acc: 0.6471\n",
      "Epoch 23/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0884 - acc: 0.9716 - val_loss: 1.7336 - val_acc: 0.6482\n",
      "Epoch 24/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0884 - acc: 0.9712 - val_loss: 1.7215 - val_acc: 0.6494\n",
      "Epoch 25/25\n",
      "30288/30288 [==============================] - 13s - loss: 0.0821 - acc: 0.9723 - val_loss: 1.7196 - val_acc: 0.6482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f801c4170f0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import *\n",
    "bn_da_model.compile(Adagrad(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=batch_size, epochs=25, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0816 - acc: 0.9738 - val_loss: 1.7224 - val_acc: 0.6471\n",
      "Epoch 2/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0885 - acc: 0.9710 - val_loss: 1.7166 - val_acc: 0.6500\n",
      "Epoch 3/25\n",
      "30288/30288 [==============================] - 21s - loss: 0.0877 - acc: 0.9705 - val_loss: 1.7280 - val_acc: 0.6477\n",
      "Epoch 4/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0892 - acc: 0.9713 - val_loss: 1.7299 - val_acc: 0.6488\n",
      "Epoch 5/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0842 - acc: 0.9725 - val_loss: 1.7126 - val_acc: 0.6482\n",
      "Epoch 6/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0861 - acc: 0.9718 - val_loss: 1.7198 - val_acc: 0.6488\n",
      "Epoch 7/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0903 - acc: 0.9700 - val_loss: 1.7308 - val_acc: 0.6477\n",
      "Epoch 8/25\n",
      "30288/30288 [==============================] - 21s - loss: 0.0864 - acc: 0.9716 - val_loss: 1.7270 - val_acc: 0.6488\n",
      "Epoch 9/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0835 - acc: 0.9721 - val_loss: 1.7217 - val_acc: 0.6500\n",
      "Epoch 10/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0863 - acc: 0.9719 - val_loss: 1.7235 - val_acc: 0.6471\n",
      "Epoch 11/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0858 - acc: 0.9720 - val_loss: 1.7169 - val_acc: 0.6459\n",
      "Epoch 12/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0831 - acc: 0.9721 - val_loss: 1.7252 - val_acc: 0.6488\n",
      "Epoch 13/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0814 - acc: 0.9735 - val_loss: 1.7160 - val_acc: 0.6471\n",
      "Epoch 14/25\n",
      "30288/30288 [==============================] - 21s - loss: 0.0889 - acc: 0.9724 - val_loss: 1.7267 - val_acc: 0.6482\n",
      "Epoch 15/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0857 - acc: 0.9712 - val_loss: 1.7367 - val_acc: 0.6447\n",
      "Epoch 16/25\n",
      "30288/30288 [==============================] - 21s - loss: 0.0871 - acc: 0.9714 - val_loss: 1.7200 - val_acc: 0.6477\n",
      "Epoch 17/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0885 - acc: 0.9720 - val_loss: 1.7305 - val_acc: 0.6482\n",
      "Epoch 18/25\n",
      "30288/30288 [==============================] - 21s - loss: 0.0910 - acc: 0.9699 - val_loss: 1.7183 - val_acc: 0.6500\n",
      "Epoch 19/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0861 - acc: 0.9718 - val_loss: 1.7131 - val_acc: 0.6459\n",
      "Epoch 20/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0888 - acc: 0.9706 - val_loss: 1.7279 - val_acc: 0.6482\n",
      "Epoch 21/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0885 - acc: 0.9709 - val_loss: 1.7291 - val_acc: 0.6500\n",
      "Epoch 22/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0838 - acc: 0.9724 - val_loss: 1.7219 - val_acc: 0.6500\n",
      "Epoch 23/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0917 - acc: 0.9698 - val_loss: 1.7324 - val_acc: 0.6465\n",
      "Epoch 24/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0812 - acc: 0.9725 - val_loss: 1.7250 - val_acc: 0.6482\n",
      "Epoch 25/25\n",
      "30288/30288 [==============================] - 20s - loss: 0.0854 - acc: 0.9712 - val_loss: 1.7228 - val_acc: 0.6488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f807ed0f6d8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_da_model.compile(Adadelta(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=batch_size, epochs=25, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0804 - acc: 0.9723 - val_loss: 1.7197 - val_acc: 0.6376\n",
      "Epoch 2/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0852 - acc: 0.9719 - val_loss: 1.7375 - val_acc: 0.6453\n",
      "Epoch 3/25\n",
      "30288/30288 [==============================] - 16s - loss: 0.0845 - acc: 0.9723 - val_loss: 1.7081 - val_acc: 0.6441\n",
      "Epoch 4/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0888 - acc: 0.9708 - val_loss: 1.6761 - val_acc: 0.6417\n",
      "Epoch 5/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0830 - acc: 0.9726 - val_loss: 1.6833 - val_acc: 0.6506825 - acc: 0.9\n",
      "Epoch 6/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0858 - acc: 0.9707 - val_loss: 1.6899 - val_acc: 0.6447\n",
      "Epoch 7/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0823 - acc: 0.9720 - val_loss: 1.6834 - val_acc: 0.6488\n",
      "Epoch 8/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0869 - acc: 0.9717 - val_loss: 1.6802 - val_acc: 0.6447\n",
      "Epoch 9/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0824 - acc: 0.9722 - val_loss: 1.6291 - val_acc: 0.6411\n",
      "Epoch 10/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0817 - acc: 0.9735 - val_loss: 1.6684 - val_acc: 0.6435\n",
      "Epoch 11/25\n",
      "30288/30288 [==============================] - 16s - loss: 0.0810 - acc: 0.9725 - val_loss: 1.6433 - val_acc: 0.6471\n",
      "Epoch 12/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0748 - acc: 0.9750 - val_loss: 1.6324 - val_acc: 0.6482\n",
      "Epoch 13/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0778 - acc: 0.9739 - val_loss: 1.6884 - val_acc: 0.6477\n",
      "Epoch 14/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0813 - acc: 0.9730 - val_loss: 1.6623 - val_acc: 0.6488\n",
      "Epoch 15/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0820 - acc: 0.9725 - val_loss: 1.6136 - val_acc: 0.6453\n",
      "Epoch 16/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0810 - acc: 0.9739 - val_loss: 1.6337 - val_acc: 0.6465\n",
      "Epoch 17/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0762 - acc: 0.9744 - val_loss: 1.6843 - val_acc: 0.6453\n",
      "Epoch 18/25\n",
      "30288/30288 [==============================] - 16s - loss: 0.0830 - acc: 0.9728 - val_loss: 1.6370 - val_acc: 0.6453\n",
      "Epoch 19/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0804 - acc: 0.9735 - val_loss: 1.6161 - val_acc: 0.6453\n",
      "Epoch 20/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0821 - acc: 0.9725 - val_loss: 1.6367 - val_acc: 0.6435\n",
      "Epoch 21/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0796 - acc: 0.9730 - val_loss: 1.5902 - val_acc: 0.6441\n",
      "Epoch 22/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0776 - acc: 0.9735 - val_loss: 1.6258 - val_acc: 0.6441\n",
      "Epoch 23/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0766 - acc: 0.9740 - val_loss: 1.6667 - val_acc: 0.6471\n",
      "Epoch 24/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0776 - acc: 0.9730 - val_loss: 1.6507 - val_acc: 0.6423\n",
      "Epoch 25/25\n",
      "30288/30288 [==============================] - 15s - loss: 0.0812 - acc: 0.9731 - val_loss: 1.6080 - val_acc: 0.6453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f801beec668>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_da_model.compile(Adamax(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=batch_size, epochs=25, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/25\n",
      "30288/30288 [==============================] - 17s - loss: 0.0744 - acc: 0.9753 - val_loss: 1.6122 - val_acc: 0.6471\n",
      "Epoch 2/25\n",
      "30288/30288 [==============================] - 18s - loss: 0.0754 - acc: 0.9747 - val_loss: 1.7508 - val_acc: 0.6405\n",
      "Epoch 3/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0761 - acc: 0.9744 - val_loss: 1.6363 - val_acc: 0.6393\n",
      "Epoch 4/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0754 - acc: 0.9754 - val_loss: 1.7040 - val_acc: 0.6471\n",
      "Epoch 5/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0720 - acc: 0.9757 - val_loss: 1.7250 - val_acc: 0.6322\n",
      "Epoch 6/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0701 - acc: 0.9756 - val_loss: 1.7820 - val_acc: 0.6340\n",
      "Epoch 7/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0703 - acc: 0.9769 - val_loss: 1.7268 - val_acc: 0.6423\n",
      "Epoch 8/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0678 - acc: 0.9777 - val_loss: 1.6620 - val_acc: 0.6447\n",
      "Epoch 9/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0693 - acc: 0.9771 - val_loss: 1.7871 - val_acc: 0.6453\n",
      "Epoch 10/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0660 - acc: 0.9780 - val_loss: 1.7736 - val_acc: 0.6322\n",
      "Epoch 11/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0625 - acc: 0.9780 - val_loss: 1.7552 - val_acc: 0.6453\n",
      "Epoch 12/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0622 - acc: 0.9789 - val_loss: 1.8306 - val_acc: 0.6429\n",
      "Epoch 13/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0591 - acc: 0.9803 - val_loss: 1.8937 - val_acc: 0.6447\n",
      "Epoch 14/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0557 - acc: 0.9805 - val_loss: 1.7902 - val_acc: 0.6524\n",
      "Epoch 15/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0564 - acc: 0.9815 - val_loss: 1.8817 - val_acc: 0.6465\n",
      "Epoch 16/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0572 - acc: 0.9803 - val_loss: 1.9578 - val_acc: 0.6423\n",
      "Epoch 17/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0616 - acc: 0.9796 - val_loss: 1.8844 - val_acc: 0.6411\n",
      "Epoch 18/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0544 - acc: 0.9818 - val_loss: 1.9413 - val_acc: 0.6423\n",
      "Epoch 19/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0593 - acc: 0.9806 - val_loss: 1.9569 - val_acc: 0.6494\n",
      "Epoch 20/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0527 - acc: 0.9824 - val_loss: 1.8976 - val_acc: 0.6447\n",
      "Epoch 21/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0514 - acc: 0.9818 - val_loss: 1.9269 - val_acc: 0.6459\n",
      "Epoch 22/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0538 - acc: 0.9829 - val_loss: 1.8496 - val_acc: 0.6500\n",
      "Epoch 23/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0501 - acc: 0.9835 - val_loss: 1.9297 - val_acc: 0.6477\n",
      "Epoch 24/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0505 - acc: 0.9835 - val_loss: 1.9051 - val_acc: 0.6482\n",
      "Epoch 25/25\n",
      "30288/30288 [==============================] - 19s - loss: 0.0504 - acc: 0.9826 - val_loss: 1.9255 - val_acc: 0.6482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f807ebc0320>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_da_model.compile(Nadam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=batch_size, epochs=25, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions\n",
    "\n",
    "Don't forget to add clipping for Kaggle submissions as it's very important to get the best cross_entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_preds = bn_da_model.predict(conv_val_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3345426389780415"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(keras.metrics.categorical_crossentropy(val_labels, do_clip(val_preds, 0.93)).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = load_array(path+'results/conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = bn_da_model.predict(conv_test_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds,0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = path+'results/subm_18_da_vgg.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.009059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name    Type_1    Type_2    Type_3\n",
       "0      0.jpg  0.007778  0.930000  0.009059\n",
       "1      1.jpg  0.007778  0.019907  0.930000\n",
       "2     10.jpg  0.007778  0.930000  0.007778\n",
       "3    100.jpg  0.007778  0.930000  0.007778\n",
       "4  10000.jpg  0.007778  0.930000  0.007778"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'image_name', [a[8:] for a in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/testing/results/subm_18_da_vgg.csv' target='_blank'>data/testing/results/subm_18_da_vgg.csv</a><br>"
      ],
      "text/plain": [
       "/media/eric/SSD500/fastai/deeplearning1/nbs/MobileODT/data/testing/results/subm_18_da_vgg.csv"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
