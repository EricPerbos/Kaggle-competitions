{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESNET, nfolds=5, 50-15-15, patience=5, resize=96, DataAugment= zoom, optimizers.Adam, activation=sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/eric/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"..\"]).decode(\"utf8\"))\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('train_v2.csv')\n",
    "df_test = pd.read_csv('sample_submission_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'cultivation',\n",
    " 'artisinal_mine',\n",
    " 'haze',\n",
    " 'primary',\n",
    " 'slash_burn',\n",
    " 'habitation',\n",
    " 'clear',\n",
    " 'road',\n",
    " 'selective_logging',\n",
    " 'partly_cloudy',\n",
    " 'agriculture',\n",
    " 'water',\n",
    " 'cloudy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map = {'agriculture': 14,\n",
    " 'artisinal_mine': 5,\n",
    " 'bare_ground': 1,\n",
    " 'blooming': 3,\n",
    " 'blow_down': 0,\n",
    " 'clear': 10,\n",
    " 'cloudy': 16,\n",
    " 'conventional_mine': 2,\n",
    " 'cultivation': 4,\n",
    " 'habitation': 9,\n",
    " 'haze': 6,\n",
    " 'partly_cloudy': 13,\n",
    " 'primary': 7,\n",
    " 'road': 11,\n",
    " 'selective_logging': 12,\n",
    " 'slash_burn': 8,\n",
    " 'water': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [01:00<00:00, 668.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "    img = cv2.imread('./train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train.append(cv2.resize(img, (96, 96)))\n",
    "    y_train.append(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_train, np.float32)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61191/61191 [01:31<00:00, 668.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for f, tags in tqdm(df_test.values, miniters=1000):\n",
    "    img = cv2.imread('./test-jpg/{}.jpg'.format(f))\n",
    "    x_test.append(cv2.resize(img, (96, 96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test  = np.array(x_test, np.float32)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 96, 96, 3)\n",
      "(40479, 17)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfolds = 5\n",
    "\n",
    "num_fold = 0\n",
    "sum_score = 0\n",
    "\n",
    "yfull_test = []\n",
    "yfull_train =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(y_train), n_folds=nfolds, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(zoom_range=0.2, horizontal_flip=True, vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start KFold number 1 from 2\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Epoch 1/50\n",
      "253/252 [==============================] - 114s - loss: 0.2511 - acc: 0.9085 - val_loss: 0.2474 - val_acc: 0.9071\n",
      "Epoch 2/50\n",
      "253/252 [==============================] - 117s - loss: 0.1577 - acc: 0.9377 - val_loss: 0.1707 - val_acc: 0.9344\n",
      "Epoch 3/50\n",
      "253/252 [==============================] - 117s - loss: 0.1475 - acc: 0.9418 - val_loss: 0.1402 - val_acc: 0.9450\n",
      "Epoch 4/50\n",
      "253/252 [==============================] - 116s - loss: 0.1406 - acc: 0.9447 - val_loss: 0.1355 - val_acc: 0.9483\n",
      "Epoch 5/50\n",
      "253/252 [==============================] - 117s - loss: 0.1345 - acc: 0.9473 - val_loss: 0.1341 - val_acc: 0.9480\n",
      "Epoch 6/50\n",
      "253/252 [==============================] - 115s - loss: 0.1296 - acc: 0.9497 - val_loss: 0.1478 - val_acc: 0.9461\n",
      "Epoch 7/50\n",
      "253/252 [==============================] - 115s - loss: 0.1268 - acc: 0.9504 - val_loss: 0.1367 - val_acc: 0.9494\n",
      "Epoch 8/50\n",
      "253/252 [==============================] - 117s - loss: 0.1235 - acc: 0.9522 - val_loss: 0.1235 - val_acc: 0.9510\n",
      "Epoch 9/50\n",
      "253/252 [==============================] - 117s - loss: 0.1214 - acc: 0.9531 - val_loss: 0.1173 - val_acc: 0.9553\n",
      "Epoch 10/50\n",
      "253/252 [==============================] - 115s - loss: 0.1186 - acc: 0.9541 - val_loss: 0.1291 - val_acc: 0.9505\n",
      "Epoch 11/50\n",
      "253/252 [==============================] - 115s - loss: 0.1168 - acc: 0.9552 - val_loss: 0.1179 - val_acc: 0.9557\n",
      "Epoch 12/50\n",
      "253/252 [==============================] - 117s - loss: 0.1145 - acc: 0.9562 - val_loss: 0.1106 - val_acc: 0.9575\n",
      "Epoch 13/50\n",
      "253/252 [==============================] - 116s - loss: 0.1137 - acc: 0.9563 - val_loss: 0.1127 - val_acc: 0.9558\n",
      "Epoch 14/50\n",
      "253/252 [==============================] - 117s - loss: 0.1115 - acc: 0.9570 - val_loss: 0.1089 - val_acc: 0.9586\n",
      "Epoch 15/50\n",
      "253/252 [==============================] - 115s - loss: 0.1103 - acc: 0.9574 - val_loss: 0.1110 - val_acc: 0.9586\n",
      "Epoch 16/50\n",
      "253/252 [==============================] - 117s - loss: 0.1107 - acc: 0.9571 - val_loss: 0.1080 - val_acc: 0.9590\n",
      "Epoch 17/50\n",
      "253/252 [==============================] - 117s - loss: 0.1091 - acc: 0.9581 - val_loss: 0.1073 - val_acc: 0.9584\n",
      "Epoch 18/50\n",
      "253/252 [==============================] - 117s - loss: 0.1081 - acc: 0.9585 - val_loss: 0.1049 - val_acc: 0.9605\n",
      "Epoch 19/50\n",
      "253/252 [==============================] - 115s - loss: 0.1073 - acc: 0.9589 - val_loss: 0.1098 - val_acc: 0.9584\n",
      "Epoch 20/50\n",
      "253/252 [==============================] - 117s - loss: 0.1068 - acc: 0.9592 - val_loss: 0.1038 - val_acc: 0.9602\n",
      "Epoch 21/50\n",
      "253/252 [==============================] - 115s - loss: 0.1061 - acc: 0.9592 - val_loss: 0.1075 - val_acc: 0.9588\n",
      "Epoch 22/50\n",
      "253/252 [==============================] - 115s - loss: 0.1061 - acc: 0.9591 - val_loss: 0.1118 - val_acc: 0.9583\n",
      "Epoch 23/50\n",
      "253/252 [==============================] - 115s - loss: 0.1052 - acc: 0.9596 - val_loss: 0.1057 - val_acc: 0.9603\n",
      "Epoch 24/50\n",
      "253/252 [==============================] - 117s - loss: 0.1036 - acc: 0.9602 - val_loss: 0.1015 - val_acc: 0.9619\n",
      "Epoch 25/50\n",
      "253/252 [==============================] - 116s - loss: 0.1037 - acc: 0.9603 - val_loss: 0.1051 - val_acc: 0.9597\n",
      "Epoch 26/50\n",
      "253/252 [==============================] - 118s - loss: 0.1034 - acc: 0.9603 - val_loss: 0.1013 - val_acc: 0.9613\n",
      "Epoch 27/50\n",
      "253/252 [==============================] - 116s - loss: 0.1032 - acc: 0.9604 - val_loss: 0.1021 - val_acc: 0.9612\n",
      "Epoch 28/50\n",
      "253/252 [==============================] - 117s - loss: 0.1014 - acc: 0.9612 - val_loss: 0.1004 - val_acc: 0.9624\n",
      "Epoch 29/50\n",
      "253/252 [==============================] - 115s - loss: 0.1022 - acc: 0.9609 - val_loss: 0.1006 - val_acc: 0.9616\n",
      "Epoch 30/50\n",
      "253/252 [==============================] - 117s - loss: 0.1010 - acc: 0.9609 - val_loss: 0.1015 - val_acc: 0.9617\n",
      "Epoch 31/50\n",
      "253/252 [==============================] - 117s - loss: 0.1010 - acc: 0.9612 - val_loss: 0.1006 - val_acc: 0.9610\n",
      "Epoch 32/50\n",
      "253/252 [==============================] - 116s - loss: 0.1001 - acc: 0.9615 - val_loss: 0.1035 - val_acc: 0.9606\n",
      "Epoch 33/50\n",
      "253/252 [==============================] - 118s - loss: 0.0999 - acc: 0.9615 - val_loss: 0.0978 - val_acc: 0.9626\n",
      "Epoch 34/50\n",
      "253/252 [==============================] - 116s - loss: 0.0993 - acc: 0.9618 - val_loss: 0.1055 - val_acc: 0.9609\n",
      "Epoch 35/50\n",
      "253/252 [==============================] - 116s - loss: 0.0996 - acc: 0.9617 - val_loss: 0.1005 - val_acc: 0.9609\n",
      "Epoch 36/50\n",
      "253/252 [==============================] - 116s - loss: 0.0985 - acc: 0.9622 - val_loss: 0.0991 - val_acc: 0.9626\n",
      "Epoch 37/50\n",
      "253/252 [==============================] - 116s - loss: 0.0988 - acc: 0.9621 - val_loss: 0.1020 - val_acc: 0.9621\n",
      "Epoch 38/50\n",
      "253/252 [==============================] - 116s - loss: 0.0994 - acc: 0.9618 - val_loss: 0.0983 - val_acc: 0.9630\n",
      "Epoch 39/50\n",
      "253/252 [==============================] - 116s - loss: 0.0974 - acc: 0.9628 - val_loss: 0.1000 - val_acc: 0.9622\n",
      "Epoch 1/15\n",
      "253/252 [==============================] - 119s - loss: 0.0928 - acc: 0.9643 - val_loss: 0.0947 - val_acc: 0.9636\n",
      "Epoch 2/15\n",
      "253/252 [==============================] - 119s - loss: 0.0909 - acc: 0.9649 - val_loss: 0.0930 - val_acc: 0.9646\n",
      "Epoch 3/15\n",
      "253/252 [==============================] - 117s - loss: 0.0905 - acc: 0.9649 - val_loss: 0.0941 - val_acc: 0.9634\n",
      "Epoch 4/15\n",
      "253/252 [==============================] - 118s - loss: 0.0896 - acc: 0.9653 - val_loss: 0.0935 - val_acc: 0.9642\n",
      "Epoch 5/15\n",
      "253/252 [==============================] - 118s - loss: 0.0896 - acc: 0.9652 - val_loss: 0.0934 - val_acc: 0.9644\n",
      "Epoch 6/15\n",
      "253/252 [==============================] - 119s - loss: 0.0894 - acc: 0.9655 - val_loss: 0.0920 - val_acc: 0.9650\n",
      "Epoch 7/15\n",
      "253/252 [==============================] - 118s - loss: 0.0892 - acc: 0.9655 - val_loss: 0.0915 - val_acc: 0.9651\n",
      "Epoch 8/15\n",
      "253/252 [==============================] - 116s - loss: 0.0893 - acc: 0.9655 - val_loss: 0.0917 - val_acc: 0.9651\n",
      "Epoch 9/15\n",
      "253/252 [==============================] - 117s - loss: 0.0891 - acc: 0.9654 - val_loss: 0.0935 - val_acc: 0.9648\n",
      "Epoch 10/15\n",
      "253/252 [==============================] - 114s - loss: 0.0884 - acc: 0.9656 - val_loss: 0.0940 - val_acc: 0.9637\n",
      "Epoch 11/15\n",
      "253/252 [==============================] - 111s - loss: 0.0883 - acc: 0.9657 - val_loss: 0.0927 - val_acc: 0.9644\n",
      "Epoch 12/15\n",
      "253/252 [==============================] - 111s - loss: 0.0882 - acc: 0.9660 - val_loss: 0.0927 - val_acc: 0.9647\n",
      "Epoch 13/15\n",
      "253/252 [==============================] - 111s - loss: 0.0877 - acc: 0.9658 - val_loss: 0.0928 - val_acc: 0.9644\n",
      "Epoch 1/15\n",
      "253/252 [==============================] - 115s - loss: 0.0875 - acc: 0.9661 - val_loss: 0.0918 - val_acc: 0.9652\n",
      "Epoch 2/15\n",
      "253/252 [==============================] - 117s - loss: 0.0873 - acc: 0.9661 - val_loss: 0.0919 - val_acc: 0.9648\n",
      "Epoch 3/15\n",
      "253/252 [==============================] - 118s - loss: 0.0880 - acc: 0.9660 - val_loss: 0.0912 - val_acc: 0.9653\n",
      "Epoch 4/15\n",
      "253/252 [==============================] - 116s - loss: 0.0867 - acc: 0.9662 - val_loss: 0.0936 - val_acc: 0.9645\n",
      "Epoch 5/15\n",
      "253/252 [==============================] - 117s - loss: 0.0875 - acc: 0.9662 - val_loss: 0.0917 - val_acc: 0.9654\n",
      "Epoch 6/15\n",
      "253/252 [==============================] - 117s - loss: 0.0877 - acc: 0.9662 - val_loss: 0.0922 - val_acc: 0.9651\n",
      "Epoch 7/15\n",
      "253/252 [==============================] - 117s - loss: 0.0871 - acc: 0.9661 - val_loss: 0.0913 - val_acc: 0.9649\n",
      "Epoch 8/15\n",
      "253/252 [==============================] - 116s - loss: 0.0867 - acc: 0.9663 - val_loss: 0.0922 - val_acc: 0.9652\n",
      "Epoch 9/15\n",
      "253/252 [==============================] - 116s - loss: 0.0877 - acc: 0.9661 - val_loss: 0.0914 - val_acc: 0.9649\n",
      "0.924377296836\n",
      "Start KFold number 2 from 2\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Epoch 1/50\n",
      "253/252 [==============================] - 123s - loss: 0.3027 - acc: 0.8875 - val_loss: 0.2572 - val_acc: 0.9049\n",
      "Epoch 2/50\n",
      "253/252 [==============================] - 118s - loss: 0.1861 - acc: 0.9266 - val_loss: 0.1890 - val_acc: 0.9221\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253/252 [==============================] - 118s - loss: 0.1647 - acc: 0.9339 - val_loss: 0.1703 - val_acc: 0.9308\n",
      "Epoch 4/50\n",
      "253/252 [==============================] - 119s - loss: 0.1574 - acc: 0.9368 - val_loss: 0.1622 - val_acc: 0.9355\n",
      "Epoch 5/50\n",
      "253/252 [==============================] - 118s - loss: 0.1467 - acc: 0.9412 - val_loss: 0.1404 - val_acc: 0.9429\n",
      "Epoch 6/50\n",
      "253/252 [==============================] - 120s - loss: 0.1400 - acc: 0.9440 - val_loss: 0.1355 - val_acc: 0.9470\n",
      "Epoch 7/50\n",
      "253/252 [==============================] - 117s - loss: 0.1364 - acc: 0.9463 - val_loss: 0.1478 - val_acc: 0.9436\n",
      "Epoch 8/50\n",
      "253/252 [==============================] - 119s - loss: 0.1328 - acc: 0.9481 - val_loss: 0.1245 - val_acc: 0.9523\n",
      "Epoch 9/50\n",
      "253/252 [==============================] - 117s - loss: 0.1278 - acc: 0.9499 - val_loss: 0.1323 - val_acc: 0.9499\n",
      "Epoch 10/50\n",
      "253/252 [==============================] - 119s - loss: 0.1250 - acc: 0.9513 - val_loss: 0.1243 - val_acc: 0.9504\n",
      "Epoch 11/50\n",
      "253/252 [==============================] - 119s - loss: 0.1224 - acc: 0.9519 - val_loss: 0.1207 - val_acc: 0.9528\n",
      "Epoch 12/50\n",
      "253/252 [==============================] - 117s - loss: 0.1232 - acc: 0.9519 - val_loss: 0.1216 - val_acc: 0.9536\n",
      "Epoch 13/50\n",
      "253/252 [==============================] - 117s - loss: 0.1252 - acc: 0.9512 - val_loss: 0.1444 - val_acc: 0.9464\n",
      "Epoch 14/50\n",
      "253/252 [==============================] - 118s - loss: 0.1249 - acc: 0.9514 - val_loss: 0.1202 - val_acc: 0.9535\n",
      "Epoch 15/50\n",
      "253/252 [==============================] - 116s - loss: 0.1179 - acc: 0.9544 - val_loss: 0.1213 - val_acc: 0.9533\n",
      "Epoch 16/50\n",
      "253/252 [==============================] - 120s - loss: 0.1152 - acc: 0.9553 - val_loss: 0.1122 - val_acc: 0.9564\n",
      "Epoch 17/50\n",
      "253/252 [==============================] - 117s - loss: 0.1148 - acc: 0.9555 - val_loss: 0.1151 - val_acc: 0.9563\n",
      "Epoch 18/50\n",
      "253/252 [==============================] - 120s - loss: 0.1125 - acc: 0.9565 - val_loss: 0.1117 - val_acc: 0.9579\n",
      "Epoch 19/50\n",
      "253/252 [==============================] - 119s - loss: 0.1109 - acc: 0.9572 - val_loss: 0.1109 - val_acc: 0.9578\n",
      "Epoch 20/50\n",
      "253/252 [==============================] - 119s - loss: 0.1091 - acc: 0.9582 - val_loss: 0.1049 - val_acc: 0.9594\n",
      "Epoch 21/50\n",
      "253/252 [==============================] - 118s - loss: 0.1079 - acc: 0.9587 - val_loss: 0.1069 - val_acc: 0.9586\n",
      "Epoch 22/50\n",
      "253/252 [==============================] - 119s - loss: 0.1068 - acc: 0.9589 - val_loss: 0.1037 - val_acc: 0.9602\n",
      "Epoch 23/50\n",
      "253/252 [==============================] - 118s - loss: 0.1059 - acc: 0.9595 - val_loss: 0.1070 - val_acc: 0.9597\n",
      "Epoch 24/50\n",
      "253/252 [==============================] - 118s - loss: 0.1054 - acc: 0.9595 - val_loss: 0.1032 - val_acc: 0.9602\n",
      "Epoch 25/50\n",
      "253/252 [==============================] - 119s - loss: 0.1043 - acc: 0.9598 - val_loss: 0.1005 - val_acc: 0.9616\n",
      "Epoch 26/50\n",
      "253/252 [==============================] - 116s - loss: 0.1038 - acc: 0.9600 - val_loss: 0.1029 - val_acc: 0.9604\n",
      "Epoch 27/50\n",
      "253/252 [==============================] - 117s - loss: 0.1029 - acc: 0.9603 - val_loss: 0.1113 - val_acc: 0.9584\n",
      "Epoch 28/50\n",
      "253/252 [==============================] - 118s - loss: 0.1034 - acc: 0.9604 - val_loss: 0.1077 - val_acc: 0.9588\n",
      "Epoch 29/50\n",
      "253/252 [==============================] - 119s - loss: 0.1027 - acc: 0.9606 - val_loss: 0.1003 - val_acc: 0.9619\n",
      "Epoch 30/50\n",
      "253/252 [==============================] - 119s - loss: 0.1012 - acc: 0.9612 - val_loss: 0.1003 - val_acc: 0.9616\n",
      "Epoch 31/50\n",
      "253/252 [==============================] - 120s - loss: 0.1005 - acc: 0.9614 - val_loss: 0.0986 - val_acc: 0.9628\n",
      "Epoch 32/50\n",
      "253/252 [==============================] - 118s - loss: 0.0994 - acc: 0.9618 - val_loss: 0.0992 - val_acc: 0.9616\n",
      "Epoch 33/50\n",
      "253/252 [==============================] - 118s - loss: 0.1003 - acc: 0.9615 - val_loss: 0.1120 - val_acc: 0.9613\n",
      "Epoch 34/50\n",
      "253/252 [==============================] - 118s - loss: 0.0998 - acc: 0.9616 - val_loss: 0.0964 - val_acc: 0.9632\n",
      "Epoch 35/50\n",
      "253/252 [==============================] - 117s - loss: 0.0981 - acc: 0.9625 - val_loss: 0.0998 - val_acc: 0.9619\n",
      "Epoch 36/50\n",
      "253/252 [==============================] - 117s - loss: 0.0973 - acc: 0.9624 - val_loss: 0.0989 - val_acc: 0.9627\n",
      "Epoch 37/50\n",
      "253/252 [==============================] - 117s - loss: 0.0985 - acc: 0.9622 - val_loss: 0.1022 - val_acc: 0.9618\n",
      "Epoch 38/50\n",
      "253/252 [==============================] - 117s - loss: 0.0968 - acc: 0.9629 - val_loss: 0.0991 - val_acc: 0.9623\n",
      "Epoch 39/50\n",
      "253/252 [==============================] - 117s - loss: 0.0963 - acc: 0.9627 - val_loss: 0.0986 - val_acc: 0.9626\n",
      "Epoch 40/50\n",
      "253/252 [==============================] - 118s - loss: 0.0954 - acc: 0.9631 - val_loss: 0.0982 - val_acc: 0.9625\n",
      "Epoch 1/15\n",
      "253/252 [==============================] - 121s - loss: 0.0900 - acc: 0.9655 - val_loss: 0.0928 - val_acc: 0.9649\n",
      "Epoch 2/15\n",
      "253/252 [==============================] - 117s - loss: 0.0894 - acc: 0.9653 - val_loss: 0.0931 - val_acc: 0.9646\n",
      "Epoch 3/15\n",
      "253/252 [==============================] - 119s - loss: 0.0888 - acc: 0.9656 - val_loss: 0.0917 - val_acc: 0.9649\n",
      "Epoch 4/15\n",
      "253/252 [==============================] - 117s - loss: 0.0883 - acc: 0.9659 - val_loss: 0.0921 - val_acc: 0.9647\n",
      "Epoch 5/15\n",
      "253/252 [==============================] - 119s - loss: 0.0877 - acc: 0.9660 - val_loss: 0.0907 - val_acc: 0.9656\n",
      "Epoch 6/15\n",
      "253/252 [==============================] - 117s - loss: 0.0876 - acc: 0.9662 - val_loss: 0.0922 - val_acc: 0.9648\n",
      "Epoch 7/15\n",
      "253/252 [==============================] - 117s - loss: 0.0878 - acc: 0.9660 - val_loss: 0.0916 - val_acc: 0.9658\n",
      "Epoch 8/15\n",
      "253/252 [==============================] - 117s - loss: 0.0870 - acc: 0.9662 - val_loss: 0.0925 - val_acc: 0.9651\n",
      "Epoch 9/15\n",
      "253/252 [==============================] - 117s - loss: 0.0872 - acc: 0.9663 - val_loss: 0.0907 - val_acc: 0.9657\n",
      "Epoch 10/15\n",
      "253/252 [==============================] - 118s - loss: 0.0871 - acc: 0.9660 - val_loss: 0.0903 - val_acc: 0.9656\n",
      "Epoch 11/15\n",
      "253/252 [==============================] - 117s - loss: 0.0866 - acc: 0.9664 - val_loss: 0.0931 - val_acc: 0.9649\n",
      "Epoch 12/15\n",
      "253/252 [==============================] - 118s - loss: 0.0872 - acc: 0.9661 - val_loss: 0.0914 - val_acc: 0.9655\n",
      "Epoch 13/15\n",
      "253/252 [==============================] - 117s - loss: 0.0863 - acc: 0.9664 - val_loss: 0.0910 - val_acc: 0.9661\n",
      "Epoch 14/15\n",
      "253/252 [==============================] - 117s - loss: 0.0856 - acc: 0.9670 - val_loss: 0.0913 - val_acc: 0.9653\n",
      "Epoch 15/15\n",
      "253/252 [==============================] - 118s - loss: 0.0857 - acc: 0.9666 - val_loss: 0.0887 - val_acc: 0.9662\n",
      "Epoch 1/15\n",
      "253/252 [==============================] - 120s - loss: 0.0850 - acc: 0.9668 - val_loss: 0.0909 - val_acc: 0.9657\n",
      "Epoch 2/15\n",
      "253/252 [==============================] - 119s - loss: 0.0852 - acc: 0.9668 - val_loss: 0.0896 - val_acc: 0.9666\n",
      "Epoch 3/15\n",
      "253/252 [==============================] - 117s - loss: 0.0852 - acc: 0.9668 - val_loss: 0.0925 - val_acc: 0.9643\n",
      "Epoch 4/15\n",
      "253/252 [==============================] - 117s - loss: 0.0852 - acc: 0.9669 - val_loss: 0.0913 - val_acc: 0.9656\n",
      "Epoch 5/15\n",
      "253/252 [==============================] - 117s - loss: 0.0847 - acc: 0.9670 - val_loss: 0.0918 - val_acc: 0.9655\n",
      "Epoch 6/15\n",
      "253/252 [==============================] - 118s - loss: 0.0851 - acc: 0.9668 - val_loss: 0.0904 - val_acc: 0.9654\n",
      "Epoch 7/15\n",
      "253/252 [==============================] - 117s - loss: 0.0847 - acc: 0.9671 - val_loss: 0.0916 - val_acc: 0.9656\n",
      "Epoch 8/15\n",
      "253/252 [==============================] - 117s - loss: 0.0848 - acc: 0.9668 - val_loss: 0.0900 - val_acc: 0.9656\n",
      "0.92341784016\n",
      "Start KFold number 3 from 2\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Epoch 1/50\n",
      " 43/252 [====>.........................] - ETA: 101s - loss: 0.6307 - acc: 0.7169"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9b4484eb4cbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                             workers=4)\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfold_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1901\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf:\n",
    "        start_time_model_fitting = time.time()\n",
    "        \n",
    "        X_train = x_train[train_index]\n",
    "        Y_train = y_train[train_index]\n",
    "        X_valid = x_train[test_index]\n",
    "        Y_valid = y_train[test_index]\n",
    "\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "        \n",
    "        kfold_weights_path = os.path.join('', 'weights_kfold_' + str(num_fold) + '.h5')\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(BatchNormalization(input_shape=(96, 96,3)))\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(256, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "             \n",
    "        model.add(Conv2D(512, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(512, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(1024, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "        epochs_arr = [50, 15, 15]\n",
    "        learn_rates = [0.001, 0.0001, 0.00001]\n",
    "\n",
    "        for learn_rate, epochs in zip(learn_rates, epochs_arr):\n",
    "            opt  = optimizers.Adam(lr=learn_rate)\n",
    "            model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "            callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
    "            ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)]\n",
    "\n",
    "            #model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n",
    "                  #batch_size=128,verbose=2, epochs=epochs,callbacks=callbacks,shuffle=True)\n",
    "            \n",
    "            model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                            validation_data=datagen.flow(X_valid, Y_valid, batch_size=batch_size),\n",
    "                            validation_steps=len(X_valid) / batch_size,\n",
    "                            steps_per_epoch=len(X_train) / batch_size,\n",
    "                            epochs=epochs,\n",
    "                            callbacks=callbacks,\n",
    "                            workers=4)\n",
    "        \n",
    "        if os.path.isfile(kfold_weights_path):\n",
    "            model.load_weights(kfold_weights_path)\n",
    "        \n",
    "        p_valid = model.predict(X_valid, batch_size = batch_size, verbose=2)\n",
    "        print(fbeta_score(Y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))\n",
    "\n",
    "        p_train = model.predict(x_train, batch_size = batch_size, verbose=2)\n",
    "        yfull_train.append(p_train)\n",
    "        \n",
    "        p_test = model.predict(x_test, batch_size = batch_size, verbose=2)\n",
    "        yfull_test.append(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blow_down</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>blooming</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>haze</th>\n",
       "      <th>primary</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>habitation</th>\n",
       "      <th>clear</th>\n",
       "      <th>road</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>water</th>\n",
       "      <th>cloudy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.696447e-04</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>2.406719e-05</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>3.936566e-05</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.993404</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>1.430247e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.865900e-04</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>2.516026e-05</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>5.138692e-05</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.999611</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.988229</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.012013</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>2.138614e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.489264e-05</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>3.589628e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>5.694415e-07</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.998531</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.036455</td>\n",
       "      <td>2.765786e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.049254e-03</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>1.754835e-04</td>\n",
       "      <td>0.032438</td>\n",
       "      <td>0.287778</td>\n",
       "      <td>2.303507e-04</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>0.857192</td>\n",
       "      <td>0.017480</td>\n",
       "      <td>0.015993</td>\n",
       "      <td>0.151342</td>\n",
       "      <td>0.400219</td>\n",
       "      <td>0.026378</td>\n",
       "      <td>9.126219e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.017369e-05</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>7.303674e-06</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>8.314435e-06</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.739574</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.729270</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.030751</td>\n",
       "      <td>2.682497e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.116224e-04</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>7.282159e-06</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>7.089475e-06</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.999242</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>2.557572e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.681561e-04</td>\n",
       "      <td>0.017438</td>\n",
       "      <td>9.201771e-04</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.535426</td>\n",
       "      <td>3.565052e-04</td>\n",
       "      <td>0.272234</td>\n",
       "      <td>0.998971</td>\n",
       "      <td>0.010898</td>\n",
       "      <td>0.889062</td>\n",
       "      <td>0.213085</td>\n",
       "      <td>0.119661</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.506714</td>\n",
       "      <td>0.669601</td>\n",
       "      <td>0.046895</td>\n",
       "      <td>4.614639e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.617710e-05</td>\n",
       "      <td>0.033432</td>\n",
       "      <td>9.706481e-05</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>4.180264e-05</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.565448</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.996331</td>\n",
       "      <td>0.984489</td>\n",
       "      <td>0.995254</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>0.239047</td>\n",
       "      <td>0.052621</td>\n",
       "      <td>4.499381e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.329217e-04</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>3.048430e-05</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>4.373241e-05</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.998490</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>1.412200e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.093076e-04</td>\n",
       "      <td>0.029276</td>\n",
       "      <td>2.344564e-04</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.272910</td>\n",
       "      <td>8.406038e-05</td>\n",
       "      <td>0.766305</td>\n",
       "      <td>0.995795</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>0.230813</td>\n",
       "      <td>0.046950</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.835578</td>\n",
       "      <td>0.055082</td>\n",
       "      <td>1.238573e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.328109e-05</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.857698e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>2.076401e-06</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.997057</td>\n",
       "      <td>0.017285</td>\n",
       "      <td>0.075780</td>\n",
       "      <td>1.426033e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.003471e-04</td>\n",
       "      <td>0.012327</td>\n",
       "      <td>3.792904e-06</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.934047</td>\n",
       "      <td>4.500028e-05</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.109980</td>\n",
       "      <td>0.033648</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.654956</td>\n",
       "      <td>0.012965</td>\n",
       "      <td>2.968491e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.022829e-06</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>3.253543e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>3.937059e-07</td>\n",
       "      <td>0.032088</td>\n",
       "      <td>0.049829</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>9.582552e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.850491e-03</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>2.864309e-04</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.215620</td>\n",
       "      <td>1.358377e-04</td>\n",
       "      <td>0.009472</td>\n",
       "      <td>0.995003</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>0.019482</td>\n",
       "      <td>0.968347</td>\n",
       "      <td>0.145423</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>0.931517</td>\n",
       "      <td>0.040127</td>\n",
       "      <td>7.178986e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.051337e-03</td>\n",
       "      <td>0.014456</td>\n",
       "      <td>1.384876e-04</td>\n",
       "      <td>0.010622</td>\n",
       "      <td>0.508254</td>\n",
       "      <td>1.584993e-04</td>\n",
       "      <td>0.058928</td>\n",
       "      <td>0.999519</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.921380</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.394088</td>\n",
       "      <td>0.022123</td>\n",
       "      <td>2.576602e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.891852e-03</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>1.382211e-04</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.078786</td>\n",
       "      <td>1.433395e-04</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.998893</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.005648</td>\n",
       "      <td>0.995583</td>\n",
       "      <td>0.025809</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.139385</td>\n",
       "      <td>0.037264</td>\n",
       "      <td>4.060222e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.418384e-04</td>\n",
       "      <td>0.025785</td>\n",
       "      <td>1.656781e-04</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.435375</td>\n",
       "      <td>4.258112e-04</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.998470</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.976469</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.897040</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.869956</td>\n",
       "      <td>0.098110</td>\n",
       "      <td>6.575301e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.801557e-04</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>8.785797e-06</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>1.284186e-05</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.045735</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.945608</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>1.258668e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.252162e-05</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>2.201969e-05</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>1.214953e-05</td>\n",
       "      <td>0.494218</td>\n",
       "      <td>0.998926</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.530012</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>3.265141e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.376663e-05</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>2.985519e-05</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>6.184347e-05</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.006315</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.730209</td>\n",
       "      <td>0.034648</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.941583</td>\n",
       "      <td>6.047058e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.172512e-03</td>\n",
       "      <td>0.022441</td>\n",
       "      <td>7.777425e-04</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.131111</td>\n",
       "      <td>7.288136e-04</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.998914</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.998669</td>\n",
       "      <td>0.161181</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.452621</td>\n",
       "      <td>0.917307</td>\n",
       "      <td>1.304576e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.493621e-05</td>\n",
       "      <td>0.006487</td>\n",
       "      <td>3.532162e-05</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.026343</td>\n",
       "      <td>5.567045e-05</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.994814</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.100705</td>\n",
       "      <td>0.985246</td>\n",
       "      <td>0.083745</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.011653</td>\n",
       "      <td>0.253733</td>\n",
       "      <td>0.981984</td>\n",
       "      <td>1.263163e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.958389e-05</td>\n",
       "      <td>0.005889</td>\n",
       "      <td>1.794730e-04</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>1.370298e-04</td>\n",
       "      <td>0.021383</td>\n",
       "      <td>0.992982</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.590994</td>\n",
       "      <td>0.971724</td>\n",
       "      <td>0.901431</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.991345</td>\n",
       "      <td>0.170221</td>\n",
       "      <td>1.062859e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.342645e-06</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>7.805532e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>7.422270e-07</td>\n",
       "      <td>0.035418</td>\n",
       "      <td>0.036864</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.014077</td>\n",
       "      <td>9.646109e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.084768e-04</td>\n",
       "      <td>0.033562</td>\n",
       "      <td>1.104688e-03</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.033570</td>\n",
       "      <td>1.061997e-04</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.797829</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.312265</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.883100</td>\n",
       "      <td>0.125549</td>\n",
       "      <td>3.322715e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.402431e-04</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>5.722449e-06</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>8.913397e-06</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.999202</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>3.138822e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.840389e-07</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.644408e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.096696</td>\n",
       "      <td>2.487831e-08</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.992405</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.048366</td>\n",
       "      <td>0.024635</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.982787</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.072596</td>\n",
       "      <td>1.241298e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.980757e-04</td>\n",
       "      <td>0.101305</td>\n",
       "      <td>2.233269e-04</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.085595</td>\n",
       "      <td>8.841620e-05</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.943246</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>0.024185</td>\n",
       "      <td>0.985527</td>\n",
       "      <td>0.239530</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.894349</td>\n",
       "      <td>0.075059</td>\n",
       "      <td>4.860028e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.762460e-04</td>\n",
       "      <td>0.052227</td>\n",
       "      <td>3.246349e-03</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>1.244126e-04</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.786936</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.015426</td>\n",
       "      <td>0.015989</td>\n",
       "      <td>0.793054</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.974347</td>\n",
       "      <td>0.933075</td>\n",
       "      <td>0.154706</td>\n",
       "      <td>1.021634e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.393671e-04</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>1.933080e-05</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>2.555789e-05</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.995170</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>0.006819</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>1.004970e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61161</th>\n",
       "      <td>3.712339e-03</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>6.802408e-05</td>\n",
       "      <td>0.007529</td>\n",
       "      <td>0.664804</td>\n",
       "      <td>8.358648e-05</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>0.013680</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.995209</td>\n",
       "      <td>0.008964</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.546476</td>\n",
       "      <td>0.025104</td>\n",
       "      <td>1.281990e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61162</th>\n",
       "      <td>3.325865e-05</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>2.952298e-06</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.339002</td>\n",
       "      <td>1.801196e-05</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>0.999045</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.878261</td>\n",
       "      <td>0.969314</td>\n",
       "      <td>0.723827</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>0.996653</td>\n",
       "      <td>0.016119</td>\n",
       "      <td>7.103017e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61163</th>\n",
       "      <td>8.920403e-04</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>2.470382e-05</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.005895</td>\n",
       "      <td>3.837213e-05</td>\n",
       "      <td>0.012161</td>\n",
       "      <td>0.999568</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.957577</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.020530</td>\n",
       "      <td>0.010479</td>\n",
       "      <td>1.632364e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61164</th>\n",
       "      <td>4.917242e-04</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>2.599251e-05</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>3.271186e-05</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.647239</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.382728</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>1.412730e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61165</th>\n",
       "      <td>1.647990e-03</td>\n",
       "      <td>0.019708</td>\n",
       "      <td>2.609052e-05</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.850990</td>\n",
       "      <td>1.663483e-04</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.050412</td>\n",
       "      <td>0.053294</td>\n",
       "      <td>0.996863</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.647126</td>\n",
       "      <td>0.019185</td>\n",
       "      <td>3.834558e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61166</th>\n",
       "      <td>2.094203e-04</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>1.072632e-05</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>1.094142e-05</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>3.776879e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61167</th>\n",
       "      <td>9.648291e-05</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.870573e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>7.130188e-08</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.046842</td>\n",
       "      <td>1.181029e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61168</th>\n",
       "      <td>3.968835e-04</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>2.057147e-05</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>4.038057e-05</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.999654</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.997495</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>1.785834e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61169</th>\n",
       "      <td>1.615806e-04</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>1.123725e-05</td>\n",
       "      <td>0.029987</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>2.879369e-05</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>0.012844</td>\n",
       "      <td>1.946134e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61170</th>\n",
       "      <td>2.504593e-04</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>1.405220e-05</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>1.470292e-05</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.998364</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.014464</td>\n",
       "      <td>5.711168e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61171</th>\n",
       "      <td>1.097280e-04</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>4.221244e-06</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.333835</td>\n",
       "      <td>1.210172e-04</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.016453</td>\n",
       "      <td>0.043877</td>\n",
       "      <td>0.983041</td>\n",
       "      <td>0.089695</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.984082</td>\n",
       "      <td>0.023441</td>\n",
       "      <td>2.944925e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61172</th>\n",
       "      <td>1.348600e-03</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>6.162963e-04</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.273582</td>\n",
       "      <td>1.728887e-04</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>0.996707</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.287971</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.996368</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.062846</td>\n",
       "      <td>0.906933</td>\n",
       "      <td>0.099121</td>\n",
       "      <td>1.413468e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61173</th>\n",
       "      <td>4.205794e-03</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>2.465809e-05</td>\n",
       "      <td>0.120230</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>3.604996e-05</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.021466</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.020418</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>1.142443e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61174</th>\n",
       "      <td>1.766247e-04</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>7.813277e-06</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>8.991875e-06</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>3.165815e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61175</th>\n",
       "      <td>2.195758e-04</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>1.266567e-05</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.496848e-05</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>5.147351e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61176</th>\n",
       "      <td>1.528114e-04</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>7.232211e-06</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>4.723495e-06</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.998712</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>5.373957e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61177</th>\n",
       "      <td>3.108730e-06</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>1.608427e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.156498</td>\n",
       "      <td>8.667721e-07</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.994244</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.178231</td>\n",
       "      <td>0.997622</td>\n",
       "      <td>0.998016</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.999432</td>\n",
       "      <td>0.069577</td>\n",
       "      <td>7.178686e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>2.372080e-04</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.846678e-05</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>3.571077e-05</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.998092</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>1.122103e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61179</th>\n",
       "      <td>4.421973e-05</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>2.317398e-04</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.119663</td>\n",
       "      <td>1.485186e-04</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.958784</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.323357</td>\n",
       "      <td>0.994407</td>\n",
       "      <td>0.985389</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.134881</td>\n",
       "      <td>4.969417e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61180</th>\n",
       "      <td>1.710872e-04</td>\n",
       "      <td>0.037972</td>\n",
       "      <td>1.090628e-04</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>1.226374e-04</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.974370</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.335098</td>\n",
       "      <td>0.998679</td>\n",
       "      <td>0.684005</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.975083</td>\n",
       "      <td>0.078270</td>\n",
       "      <td>3.310461e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61181</th>\n",
       "      <td>4.787619e-04</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>1.139773e-05</td>\n",
       "      <td>0.039364</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>3.527073e-05</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>0.998950</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>9.711281e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61182</th>\n",
       "      <td>9.372778e-05</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>3.471298e-04</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.270474</td>\n",
       "      <td>2.297022e-05</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>0.996778</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.986174</td>\n",
       "      <td>0.962171</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.842588</td>\n",
       "      <td>0.284043</td>\n",
       "      <td>9.240473e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61183</th>\n",
       "      <td>3.102311e-04</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>1.958056e-05</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>2.472942e-05</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.998698</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>8.103621e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61184</th>\n",
       "      <td>7.402533e-06</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>2.737514e-05</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.021406</td>\n",
       "      <td>5.004607e-05</td>\n",
       "      <td>0.011770</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>0.988579</td>\n",
       "      <td>0.077434</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.072310</td>\n",
       "      <td>0.994548</td>\n",
       "      <td>1.895897e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61185</th>\n",
       "      <td>3.207604e-04</td>\n",
       "      <td>0.017676</td>\n",
       "      <td>7.099151e-04</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.024273</td>\n",
       "      <td>3.442202e-03</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.629519</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.015156</td>\n",
       "      <td>0.039715</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.908145</td>\n",
       "      <td>0.267372</td>\n",
       "      <td>0.650485</td>\n",
       "      <td>8.339754e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61186</th>\n",
       "      <td>1.745414e-05</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>4.575743e-06</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>8.531475e-06</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.303783</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.333577</td>\n",
       "      <td>0.014768</td>\n",
       "      <td>0.009942</td>\n",
       "      <td>7.286332e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61187</th>\n",
       "      <td>5.255202e-04</td>\n",
       "      <td>0.006788</td>\n",
       "      <td>2.258652e-04</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>0.053685</td>\n",
       "      <td>2.184115e-04</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>0.999034</td>\n",
       "      <td>0.055955</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.135234</td>\n",
       "      <td>0.976550</td>\n",
       "      <td>2.307872e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61188</th>\n",
       "      <td>1.519505e-03</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>4.690231e-04</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.014477</td>\n",
       "      <td>2.610464e-04</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.998054</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>0.994554</td>\n",
       "      <td>0.411325</td>\n",
       "      <td>0.015445</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>0.066453</td>\n",
       "      <td>0.370177</td>\n",
       "      <td>8.326815e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61189</th>\n",
       "      <td>2.708088e-06</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>3.175799e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>1.473249e-06</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.031331</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.009410</td>\n",
       "      <td>9.617001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61190</th>\n",
       "      <td>2.940552e-05</td>\n",
       "      <td>0.025496</td>\n",
       "      <td>2.723552e-04</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>1.187911e-04</td>\n",
       "      <td>0.008928</td>\n",
       "      <td>0.678721</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.992649</td>\n",
       "      <td>0.975006</td>\n",
       "      <td>0.985866</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.018177</td>\n",
       "      <td>0.155220</td>\n",
       "      <td>0.140832</td>\n",
       "      <td>6.481995e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61191 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          blow_down  bare_ground  conventional_mine  blooming  cultivation  \\\n",
       "0      2.696447e-04     0.000358       2.406719e-05  0.006320     0.002378   \n",
       "1      8.865900e-04     0.000307       2.516026e-05  0.017380     0.004920   \n",
       "2      1.489264e-05     0.000061       3.589628e-06  0.000008     0.004887   \n",
       "3      9.049254e-03     0.007427       1.754835e-04  0.032438     0.287778   \n",
       "4      3.017369e-05     0.000129       7.303674e-06  0.000039     0.003284   \n",
       "5      2.116224e-04     0.000117       7.282159e-06  0.000250     0.001313   \n",
       "6      2.681561e-04     0.017438       9.201771e-04  0.002622     0.535426   \n",
       "7      1.617710e-05     0.033432       9.706481e-05  0.000024     0.005142   \n",
       "8      4.329217e-04     0.000307       3.048430e-05  0.000196     0.001775   \n",
       "9      2.093076e-04     0.029276       2.344564e-04  0.000253     0.272910   \n",
       "10     1.328109e-05     0.000024       5.857698e-07  0.000002     0.002664   \n",
       "11     6.003471e-04     0.012327       3.792904e-06  0.002005     0.934047   \n",
       "12     2.022829e-06     0.000016       3.253543e-08  0.000005     0.000623   \n",
       "13     3.850491e-03     0.008458       2.864309e-04  0.002812     0.215620   \n",
       "14     1.051337e-03     0.014456       1.384876e-04  0.010622     0.508254   \n",
       "15     3.891852e-03     0.004179       1.382211e-04  0.002295     0.078786   \n",
       "16     2.418384e-04     0.025785       1.656781e-04  0.000071     0.435375   \n",
       "17     1.801557e-04     0.000086       8.785797e-06  0.000081     0.004197   \n",
       "18     1.252162e-05     0.000750       2.201969e-05  0.000129     0.002571   \n",
       "19     7.376663e-05     0.000873       2.985519e-05  0.002120     0.004152   \n",
       "20     1.172512e-03     0.022441       7.777425e-04  0.005177     0.131111   \n",
       "21     3.493621e-05     0.006487       3.532162e-05  0.000124     0.026343   \n",
       "22     8.958389e-05     0.005889       1.794730e-04  0.000299     0.187400   \n",
       "23     2.342645e-06     0.000021       7.805532e-08  0.000006     0.000653   \n",
       "24     3.084768e-04     0.033562       1.104688e-03  0.000084     0.033570   \n",
       "25     1.402431e-04     0.000080       5.722449e-06  0.000359     0.000744   \n",
       "26     1.840389e-07     0.000037       4.644408e-07  0.000002     0.096696   \n",
       "27     6.980757e-04     0.101305       2.233269e-04  0.000221     0.085595   \n",
       "28     2.762460e-04     0.052227       3.246349e-03  0.000228     0.046900   \n",
       "29     4.393671e-04     0.000226       1.933080e-05  0.000254     0.002326   \n",
       "...             ...          ...                ...       ...          ...   \n",
       "61161  3.712339e-03     0.008393       6.802408e-05  0.007529     0.664804   \n",
       "61162  3.325865e-05     0.001410       2.952298e-06  0.000089     0.339002   \n",
       "61163  8.920403e-04     0.000624       2.470382e-05  0.007030     0.005895   \n",
       "61164  4.917242e-04     0.000291       2.599251e-05  0.003394     0.007585   \n",
       "61165  1.647990e-03     0.019708       2.609052e-05  0.002808     0.850990   \n",
       "61166  2.094203e-04     0.000151       1.072632e-05  0.000086     0.001117   \n",
       "61167  9.648291e-05     0.000005       4.870573e-07  0.000011     0.001011   \n",
       "61168  3.968835e-04     0.000210       2.057147e-05  0.011669     0.002128   \n",
       "61169  1.615806e-04     0.000176       1.123725e-05  0.029987     0.001433   \n",
       "61170  2.504593e-04     0.000209       1.405220e-05  0.000632     0.001810   \n",
       "61171  1.097280e-04     0.006031       4.221244e-06  0.000284     0.333835   \n",
       "61172  1.348600e-03     0.006135       6.162963e-04  0.001923     0.273582   \n",
       "61173  4.205794e-03     0.001232       2.465809e-05  0.120230     0.012247   \n",
       "61174  1.766247e-04     0.000113       7.813277e-06  0.000097     0.000931   \n",
       "61175  2.195758e-04     0.000154       1.266567e-05  0.000228     0.001200   \n",
       "61176  1.528114e-04     0.000225       7.232211e-06  0.000143     0.001411   \n",
       "61177  3.108730e-06     0.000321       1.608427e-06  0.000008     0.156498   \n",
       "61178  2.372080e-04     0.000161       1.846678e-05  0.001458     0.001343   \n",
       "61179  4.421973e-05     0.006068       2.317398e-04  0.000079     0.119663   \n",
       "61180  1.710872e-04     0.037972       1.090628e-04  0.000138     0.102764   \n",
       "61181  4.787619e-04     0.000154       1.139773e-05  0.039364     0.002018   \n",
       "61182  9.372778e-05     0.003705       3.471298e-04  0.000283     0.270474   \n",
       "61183  3.102311e-04     0.000186       1.958056e-05  0.000417     0.001487   \n",
       "61184  7.402533e-06     0.002895       2.737514e-05  0.000232     0.021406   \n",
       "61185  3.207604e-04     0.017676       7.099151e-04  0.000169     0.024273   \n",
       "61186  1.745414e-05     0.000180       4.575743e-06  0.000043     0.003195   \n",
       "61187  5.255202e-04     0.006788       2.258652e-04  0.009008     0.053685   \n",
       "61188  1.519505e-03     0.002876       4.690231e-04  0.005375     0.014477   \n",
       "61189  2.708088e-06     0.000025       3.175799e-07  0.000007     0.000432   \n",
       "61190  2.940552e-05     0.025496       2.723552e-04  0.000040     0.006687   \n",
       "\n",
       "       artisinal_mine      haze   primary  slash_burn  habitation     clear  \\\n",
       "0        3.936566e-05  0.003992  0.999663    0.000049    0.002259  0.993404   \n",
       "1        5.138692e-05  0.001310  0.999611    0.000078    0.003413  0.988229   \n",
       "2        5.694415e-07  0.000039  0.999553    0.000064    0.000748  0.000400   \n",
       "3        2.303507e-04  0.008498  0.999160    0.004483    0.006651  0.857192   \n",
       "4        8.314435e-06  0.005580  0.739574    0.000036    0.001106  0.002813   \n",
       "5        7.089475e-06  0.000235  0.999929    0.000027    0.000673  0.999242   \n",
       "6        3.565052e-04  0.272234  0.998971    0.010898    0.889062  0.213085   \n",
       "7        4.180264e-05  0.008801  0.565448    0.000031    0.996331  0.984489   \n",
       "8        4.373241e-05  0.000542  0.999669    0.000043    0.000926  0.998490   \n",
       "9        8.406038e-05  0.766305  0.995795    0.005197    0.010137  0.230813   \n",
       "10       2.076401e-06  0.000101  0.999252    0.000022    0.000268  0.000987   \n",
       "11       4.500028e-05  0.000201  0.999993    0.109980    0.033648  0.999292   \n",
       "12       3.937059e-07  0.032088  0.049829    0.000003    0.000096  0.000347   \n",
       "13       1.358377e-04  0.009472  0.995003    0.005555    0.019482  0.968347   \n",
       "14       1.584993e-04  0.058928  0.999519    0.008278    0.011589  0.921380   \n",
       "15       1.433395e-04  0.002438  0.998893    0.000829    0.005648  0.995583   \n",
       "16       4.258112e-04  0.000435  0.998470    0.008918    0.976469  0.998750   \n",
       "17       1.284186e-05  0.001030  0.999720    0.000024    0.001018  0.045735   \n",
       "18       1.214953e-05  0.494218  0.998926    0.000035    0.001152  0.530012   \n",
       "19       6.184347e-05  0.000077  0.999948    0.000049    0.006315  0.999708   \n",
       "20       7.288136e-04  0.001574  0.998914    0.003921    0.009862  0.998669   \n",
       "21       5.567045e-05  0.001537  0.994814    0.000357    0.100705  0.985246   \n",
       "22       1.370298e-04  0.021383  0.992982    0.003109    0.590994  0.971724   \n",
       "23       7.422270e-07  0.035418  0.036864    0.000005    0.000083  0.001092   \n",
       "24       1.061997e-04  0.000127  0.797829    0.000650    0.007250  0.000062   \n",
       "25       8.913397e-06  0.000311  0.999915    0.000013    0.000664  0.999202   \n",
       "26       2.487831e-08  0.000642  0.992405    0.000024    0.048366  0.024635   \n",
       "27       8.841620e-05  0.007231  0.943246    0.003814    0.024185  0.985527   \n",
       "28       1.244126e-04  0.004180  0.786936    0.000747    0.015426  0.015989   \n",
       "29       2.555789e-05  0.000966  0.999788    0.000043    0.000755  0.995170   \n",
       "...               ...       ...       ...         ...         ...       ...   \n",
       "61161    8.358648e-05  0.001530  0.999760    0.013680    0.006767  0.995209   \n",
       "61162    1.801196e-05  0.009248  0.999045    0.004595    0.878261  0.969314   \n",
       "61163    3.837213e-05  0.012161  0.999568    0.000078    0.002081  0.957577   \n",
       "61164    3.271186e-05  0.002993  0.999763    0.000069    0.001667  0.647239   \n",
       "61165    1.663483e-04  0.001338  0.999908    0.050412    0.053294  0.996863   \n",
       "61166    1.094142e-05  0.000263  0.999885    0.000029    0.000519  0.999216   \n",
       "61167    7.130188e-08  0.000008  0.999964    0.000007    0.000177  0.000058   \n",
       "61168    4.038057e-05  0.000840  0.999654    0.000054    0.002052  0.997495   \n",
       "61169    2.879369e-05  0.002342  0.999652    0.000026    0.001643  0.994444   \n",
       "61170    1.470292e-05  0.000500  0.999823    0.000040    0.001481  0.998364   \n",
       "61171    1.210172e-04  0.006844  0.999333    0.016453    0.043877  0.983041   \n",
       "61172    1.728887e-04  0.014660  0.996707    0.004023    0.287971  0.900683   \n",
       "61173    3.604996e-05  0.000546  0.999781    0.000272    0.003865  0.997051   \n",
       "61174    8.991875e-06  0.000251  0.999913    0.000025    0.000456  0.999241   \n",
       "61175    1.496848e-05  0.000327  0.999871    0.000031    0.000711  0.998978   \n",
       "61176    4.723495e-06  0.000541  0.999837    0.000033    0.000614  0.998712   \n",
       "61177    8.667721e-07  0.000479  0.994244    0.000551    0.178231  0.997622   \n",
       "61178    3.571077e-05  0.000738  0.999759    0.000030    0.001237  0.998092   \n",
       "61179    1.485186e-04  0.006289  0.958784    0.001209    0.323357  0.994407   \n",
       "61180    1.226374e-04  0.001333  0.974370    0.002899    0.335098  0.998679   \n",
       "61181    3.527073e-05  0.000271  0.999819    0.000051    0.004691  0.998950   \n",
       "61182    2.297022e-05  0.007518  0.996778    0.002456    0.026400  0.986174   \n",
       "61183    2.472942e-05  0.000424  0.999822    0.000036    0.000862  0.998698   \n",
       "61184    5.004607e-05  0.011770  0.999414    0.000135    0.019436  0.988579   \n",
       "61185    3.442202e-03  0.005015  0.629519    0.000843    0.007491  0.015156   \n",
       "61186    8.531475e-06  0.004385  0.303783    0.000037    0.000894  0.003143   \n",
       "61187    2.184115e-04  0.000617  0.999802    0.001140    0.007887  0.999034   \n",
       "61188    2.610464e-04  0.002376  0.998054    0.000382    0.010913  0.994554   \n",
       "61189    1.473249e-06  0.026928  0.031331    0.000009    0.000073  0.006509   \n",
       "61190    1.187911e-04  0.008928  0.678721    0.000074    0.992649  0.975006   \n",
       "\n",
       "           road  selective_logging  partly_cloudy  agriculture     water  \\\n",
       "0      0.003125           0.000851       0.001140     0.006522  0.004196   \n",
       "1      0.002605           0.001984       0.010628     0.012013  0.005408   \n",
       "2      0.005297           0.000007       0.998531     0.012264  0.036455   \n",
       "3      0.017480           0.015993       0.151342     0.400219  0.026378   \n",
       "4      0.007777           0.000051       0.729270     0.014377  0.030751   \n",
       "5      0.001130           0.000086       0.000566     0.003536  0.003023   \n",
       "6      0.119661           0.003390       0.506714     0.669601  0.046895   \n",
       "7      0.995254           0.000106       0.004194     0.239047  0.052621   \n",
       "8      0.002120           0.000111       0.000923     0.004972  0.005863   \n",
       "9      0.046950           0.000337       0.008951     0.835578  0.055082   \n",
       "10     0.003517           0.000008       0.997057     0.017285  0.075780   \n",
       "11     0.023700           0.009810       0.000367     0.654956  0.012965   \n",
       "12     0.002043           0.000002       0.004760     0.005430  0.007398   \n",
       "13     0.145423           0.002113       0.011917     0.931517  0.040127   \n",
       "14     0.012436           0.005755       0.009558     0.394088  0.022123   \n",
       "15     0.025809           0.001413       0.002550     0.139385  0.037264   \n",
       "16     0.897040           0.000517       0.000766     0.869956  0.098110   \n",
       "17     0.001967           0.000046       0.945608     0.012139  0.009008   \n",
       "18     0.006614           0.000057       0.001778     0.007287  0.017200   \n",
       "19     0.730209           0.034648       0.000114     0.022579  0.941583   \n",
       "20     0.161181           0.008271       0.000533     0.452621  0.917307   \n",
       "21     0.083745           0.000094       0.011653     0.253733  0.981984   \n",
       "22     0.901431           0.000459       0.007300     0.991345  0.170221   \n",
       "23     0.001143           0.000002       0.000503     0.003815  0.014077   \n",
       "24     0.312265           0.000037       0.999255     0.883100  0.125549   \n",
       "25     0.000931           0.000065       0.000441     0.002362  0.002424   \n",
       "26     0.999759           0.000007       0.982787     0.999807  0.072596   \n",
       "27     0.239530           0.000253       0.006599     0.894349  0.075059   \n",
       "28     0.793054           0.000176       0.974347     0.933075  0.154706   \n",
       "29     0.001726           0.000086       0.004244     0.006819  0.004079   \n",
       "...         ...                ...            ...          ...       ...   \n",
       "61161  0.008964           0.004223       0.003225     0.546476  0.025104   \n",
       "61162  0.723827           0.000087       0.011619     0.996653  0.016119   \n",
       "61163  0.006835           0.001048       0.013441     0.020530  0.010479   \n",
       "61164  0.004715           0.000842       0.382728     0.012866  0.007162   \n",
       "61165  0.014289           0.003656       0.001905     0.647126  0.019185   \n",
       "61166  0.001279           0.000043       0.000503     0.003341  0.004104   \n",
       "61167  0.004668           0.000016       0.999909     0.006815  0.046842   \n",
       "61168  0.002342           0.001065       0.001160     0.006324  0.004557   \n",
       "61169  0.009286           0.003487       0.000361     0.005944  0.012844   \n",
       "61170  0.004417           0.000223       0.001080     0.005571  0.014464   \n",
       "61171  0.089695           0.000182       0.004328     0.984082  0.023441   \n",
       "61172  0.996368           0.021939       0.062846     0.906933  0.099121   \n",
       "61173  0.003201           0.021466       0.002150     0.020418  0.003844   \n",
       "61174  0.000975           0.000038       0.000452     0.002593  0.002725   \n",
       "61175  0.001114           0.000090       0.000619     0.003309  0.003011   \n",
       "61176  0.001472           0.000057       0.000563     0.003721  0.006528   \n",
       "61177  0.998016           0.000033       0.001650     0.999432  0.069577   \n",
       "61178  0.002064           0.000205       0.000831     0.004282  0.003874   \n",
       "61179  0.985389           0.000539       0.003404     0.988507  0.134881   \n",
       "61180  0.684005           0.000214       0.000752     0.975083  0.078270   \n",
       "61181  0.002328           0.004567       0.000505     0.005576  0.002579   \n",
       "61182  0.962171           0.002047       0.003645     0.842588  0.284043   \n",
       "61183  0.001421           0.000116       0.000917     0.004241  0.003551   \n",
       "61184  0.077434           0.000127       0.001479     0.072310  0.994548   \n",
       "61185  0.039715           0.000171       0.908145     0.267372  0.650485   \n",
       "61186  0.004560           0.000033       0.333577     0.014768  0.009942   \n",
       "61187  0.055955           0.007438       0.000406     0.135234  0.976550   \n",
       "61188  0.411325           0.015445       0.004353     0.066453  0.370177   \n",
       "61189  0.000575           0.000004       0.000325     0.001811  0.009410   \n",
       "61190  0.985866           0.000323       0.018177     0.155220  0.140832   \n",
       "\n",
       "             cloudy  \n",
       "0      1.430247e-04  \n",
       "1      2.138614e-04  \n",
       "2      2.765786e-04  \n",
       "3      9.126219e-04  \n",
       "4      2.682497e-01  \n",
       "5      2.557572e-05  \n",
       "6      4.614639e-04  \n",
       "7      4.499381e-04  \n",
       "8      1.412200e-04  \n",
       "9      1.238573e-03  \n",
       "10     1.426033e-04  \n",
       "11     2.968491e-06  \n",
       "12     9.582552e-01  \n",
       "13     7.178986e-04  \n",
       "14     2.576602e-04  \n",
       "15     4.060222e-04  \n",
       "16     6.575301e-06  \n",
       "17     1.258668e-04  \n",
       "18     3.265141e-04  \n",
       "19     6.047058e-06  \n",
       "20     1.304576e-04  \n",
       "21     1.263163e-04  \n",
       "22     1.062859e-04  \n",
       "23     9.646109e-01  \n",
       "24     3.322715e-03  \n",
       "25     3.138822e-05  \n",
       "26     1.241298e-06  \n",
       "27     4.860028e-04  \n",
       "28     1.021634e-03  \n",
       "29     1.004970e-04  \n",
       "...             ...  \n",
       "61161  1.281990e-04  \n",
       "61162  7.103017e-06  \n",
       "61163  1.632364e-04  \n",
       "61164  1.412730e-04  \n",
       "61165  3.834558e-05  \n",
       "61166  3.776879e-05  \n",
       "61167  1.181029e-05  \n",
       "61168  1.785834e-04  \n",
       "61169  1.946134e-04  \n",
       "61170  5.711168e-05  \n",
       "61171  2.944925e-05  \n",
       "61172  1.413468e-04  \n",
       "61173  1.142443e-04  \n",
       "61174  3.165815e-05  \n",
       "61175  5.147351e-05  \n",
       "61176  5.373957e-05  \n",
       "61177  7.178686e-07  \n",
       "61178  1.122103e-04  \n",
       "61179  4.969417e-05  \n",
       "61180  3.310461e-05  \n",
       "61181  9.711281e-05  \n",
       "61182  9.240473e-05  \n",
       "61183  8.103621e-05  \n",
       "61184  1.895897e-05  \n",
       "61185  8.339754e-02  \n",
       "61186  7.286332e-01  \n",
       "61187  2.307872e-05  \n",
       "61188  8.326815e-04  \n",
       "61189  9.617001e-01  \n",
       "61190  6.481995e-04  \n",
       "\n",
       "[61191 rows x 17 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.array(yfull_test[0])\n",
    "for i in range(1, nfolds):\n",
    "    result += np.array(yfull_test[i])\n",
    "result /= nfolds\n",
    "result = pd.DataFrame(result, columns = labels)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61191/61191 [01:40<00:00, 610.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "thres = [0.07, 0.17, 0.2, 0.04, 0.23, 0.33, 0.24, 0.22, 0.1, 0.19, 0.23, 0.24, 0.12, 0.14, 0.25, 0.26, 0.16]\n",
    "preds = []\n",
    "for i in tqdm(range(result.shape[0]), miniters=1000):\n",
    "    a = result.ix[[i]]\n",
    "    a = a.apply(lambda x: x > 0.2, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510115202891\n"
     ]
    }
   ],
   "source": [
    "p_valid = model.predict(X_valid, batch_size = 128, verbose=2)\n",
    "print(fbeta_score(Y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's save those weights.\n",
    "model.save_weights('Kele_XU_Keras_0913-Copy9-ter-ResNet50-96.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['tags'] = preds\n",
    "df_test.to_csv('submission_keras_5_fold_CV_0.9136_LB_0.913_copy9-ter-RestNet50-96.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
