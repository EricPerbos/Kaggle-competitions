{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intel MobileODT Kaggle competition\n",
    "\n",
    "https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:01:00.0)\n",
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theano version: 0.9.0\n",
      "Keras version: 2.0.3\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from __future__ import print_function, division\n",
    "from importlib import reload \n",
    "import utils_p3; reload(utils_p3)\n",
    "from utils_p3 import *\n",
    "%matplotlib inline\n",
    "from IPython.display import FileLink\n",
    "import tensorflow as tf\n",
    "import six\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "from PIL import ImageFile\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "#print(\"TensorFlow version: %s\" % tf.__version__)\n",
    "print(\"Theano version: %s\" % theano.__version__)\n",
    "print(\"Keras version: %s\" % keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_first'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME_DIR = os.getcwd()\n",
    "#path = \"data/imgs/\"\n",
    "path = \"data/testing/\"\n",
    "#path = \"data/testing/sample/\"\n",
    "batch_size = 1 # for pre-computation of last conv layer's output and the 5 augmented copies of training (OOM issue)\n",
    "#batch_size = 32 # for FCL and submission computation\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "keras.backend.image_data_format() #verify image_data_format for theano vs TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5048 images belonging to 3 classes.\n",
      "Found 1683 images belonging to 3 classes.\n",
      "Found 4018 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', batch_size=batch_size, shuffle=False)\n",
    "val_batches = get_batches(path+'valid', batch_size=batch_size, shuffle=False)\n",
    "test_batches = get_batches(path+'test', batch_size=batch_size, shuffle=False)\n",
    "steps_per_epoch = int(np.ceil(batches.samples/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.samples/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5048 images belonging to 3 classes.\n",
      "Found 1683 images belonging to 3 classes.\n",
      "Found 4018 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Imagenet conv features with VGG16\n",
    "Based on code from Statefarm_original notebook of @Jeremy, lesson 4.\n",
    "\n",
    "Since we have so little data, and it is similar to imagenet images (full color photos), using pre-trained VGG weights is likely to be helpful - in fact it seems likely that we won't need to fine-tune the convolutional layer weights much, if at all.\n",
    "\n",
    "So we can pre-compute the output of the last convolutional layer, as we did in lesson 3 when we experimented with dropout. (However this means that we can't use full data augmentation, since we can't pre-compute something that changes every image.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import our class, using VGG16 with BatchNorm\n",
    "import vgg16bn_p3; reload(vgg16bn_p3) # *_p3 version code for Python 3.6 and Keras 2.0\n",
    "from vgg16bn_p3 import Vgg16BN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: pre-compute the output of the last convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab VGG16 and find the last convolutional layer.\n",
    "vgg = Vgg16BN()\n",
    "model=vgg.model\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a new model that includes everything up to that last convolutional layer\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the outputs of that model by calculating the activations of that last convolutional layer\n",
    "conv_feat = conv_model.predict_generator(batches, int(np.ceil(batches.samples/batch_size)), workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As this takes time, save it to load it in the future\n",
    "save_array(path+'results/bn_conv_feat.dat', conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_val_feat = conv_model.predict_generator(val_batches, int(np.ceil(val_batches.samples/batch_size)), workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/bn_conv_val_feat.dat', conv_val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = conv_model.predict_generator(test_batches, int(np.ceil(test_batches.samples/batch_size)), workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/bn_conv_test_feat.dat', conv_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can look at the original model and find the last convo layer \"conv2d_13\" with output shape (none, 512, 14, 14)\n",
    "# and compare it with the shape of of our new model's output.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It's the same than \"conv2d_13\" !\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If this notebook was fully run once, we can directly reload the activations\n",
    "conv_feat = load_array(path+'results/bn_conv_feat.dat')\n",
    "conv_val_feat = load_array(path+'results/bn_conv_val_feat.dat')\n",
    "#conv_test_feat = load_array(path+'results/bn_conv_test_feat.dat')\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build new model on top, with dense layers\n",
    "Since we've pre-computed the output of the last convolutional layer, we need to create a network that takes that as input, and predicts our 3 classes.\n",
    "\n",
    "Let's try using a simplified version of VGG's dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we make 'p' a parameter to try different Dropout amounts\n",
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(3, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# quick test, verify batch_size\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# full run on 15 epochs\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, epochs=15, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/bn_conv22.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 3: Pre-computed data augmentation by making 5 augmented copies of training set\n",
    "\n",
    "We'll use our usual data augmentation parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5048 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Warning: uses HUGE amount of RAM (up to 60gb) and takes 90 mins for a simple 'batches.samples*2'\n",
    "# with batch_size=64. Check forum at\n",
    "# http://forums.fast.ai/t/state-farm-full-how-not-to-run-out-of-memory-with-vgg-da-batches-samples-5/3469/2\n",
    "# Maybe reduce batch_size and workers to 1 ? YES !!!\n",
    "# Also kernel needs a 'Restart and clear output' to clear RAM (now 15gb RAM + 12gb SWAP used),\n",
    "# so run Step 1 + 2 first, then reset and run Step 3.\n",
    "gen_t = image.ImageDataGenerator(rotation_range=30, height_shift_range=0.025, horizontal_flip=True,\n",
    "                                shear_range=0.05, width_shift_range=0.1, zoom_range=0.5)\n",
    "da_batches = get_batches(path+'train', gen_t, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = conv_model.predict_generator(da_batches, int(np.ceil(da_batches.samples*5)), workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/bn_da5_conv_feat24.dat', da_conv_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's include the real training data as well in its non-augmented form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat = load_array(path+'results/bn_conv_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = load_array(path+'results/bn_da5_conv_feat24.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat_update = np.concatenate([da_conv_feat, conv_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/bn_da5_conv_feat_update24.dat', da_conv_feat_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat_update = load_array(path+'results/bn_da5_conv_feat_update24.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since we've now got a dataset 6x bigger than before, we'll need to copy our labels 6 times too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_trn_labels = np.concatenate([trn_labels]*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/bn_da5_trn_labels24.dat', da_trn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_trn_labels = load_array(path+'results/bn_da5_trn_labels24.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Based on some experiments the previous model works well, maybe with bigger dense layers like 512 later ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we make 'p' a parameter to try different Dropout amounts\n",
    "def get_bn_da_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(3, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_da_model = Sequential(get_bn_da_layers(p))\n",
    "bn_da_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_val_feat = load_array(path+'results/bn_conv_val_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/1\n",
      "30288/30288 [==============================] - 17s - loss: 1.0852 - acc: 0.5019 - val_loss: 0.8849 - val_acc: 0.5668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe332130be0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick test, verify batch_size\n",
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=32, epochs=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/50\n",
      "30288/30288 [==============================] - 20s - loss: 0.8853 - acc: 0.5760 - val_loss: 0.8532 - val_acc: 0.5793\n",
      "Epoch 2/50\n",
      "30288/30288 [==============================] - 23s - loss: 0.8277 - acc: 0.6089 - val_loss: 0.8251 - val_acc: 0.5989\n",
      "Epoch 3/50\n",
      "30288/30288 [==============================] - 19s - loss: 0.7871 - acc: 0.6348 - val_loss: 0.8277 - val_acc: 0.6227\n",
      "Epoch 4/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7563 - acc: 0.6543 - val_loss: 0.7981 - val_acc: 0.6275\n",
      "Epoch 5/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.7301 - acc: 0.6683 - val_loss: 0.7899 - val_acc: 0.6399\n",
      "Epoch 6/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6959 - acc: 0.6878 - val_loss: 0.7857 - val_acc: 0.6578\n",
      "Epoch 7/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6753 - acc: 0.7022 - val_loss: 0.7833 - val_acc: 0.6578\n",
      "Epoch 8/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6418 - acc: 0.7202 - val_loss: 0.7927 - val_acc: 0.6500\n",
      "Epoch 9/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6267 - acc: 0.7279 - val_loss: 0.7771 - val_acc: 0.6554\n",
      "Epoch 10/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6061 - acc: 0.7367 - val_loss: 0.7881 - val_acc: 0.6566\n",
      "Epoch 11/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.5950 - acc: 0.7430 - val_loss: 0.7723 - val_acc: 0.6625\n",
      "Epoch 12/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.5640 - acc: 0.7580 - val_loss: 0.7487 - val_acc: 0.6690\n",
      "Epoch 13/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.5572 - acc: 0.7622 - val_loss: 0.7601 - val_acc: 0.6726\n",
      "Epoch 14/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.5420 - acc: 0.7718 - val_loss: 0.7494 - val_acc: 0.6702\n",
      "Epoch 15/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.5219 - acc: 0.7812 - val_loss: 0.7472 - val_acc: 0.6821\n",
      "Epoch 16/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.5144 - acc: 0.7858 - val_loss: 0.7519 - val_acc: 0.6619\n",
      "Epoch 17/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.5016 - acc: 0.7900 - val_loss: 0.7696 - val_acc: 0.6601\n",
      "Epoch 18/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.4910 - acc: 0.7975 - val_loss: 0.7576 - val_acc: 0.6827\n",
      "Epoch 19/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.4891 - acc: 0.7959 - val_loss: 0.7557 - val_acc: 0.6815\n",
      "Epoch 20/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.4692 - acc: 0.8048 - val_loss: 0.7597 - val_acc: 0.6851\n",
      "Epoch 21/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.4611 - acc: 0.8109 - val_loss: 0.7577 - val_acc: 0.6845\n",
      "Epoch 22/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.4531 - acc: 0.8110 - val_loss: 0.7994 - val_acc: 0.6684\n",
      "Epoch 23/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.4481 - acc: 0.8158 - val_loss: 0.7655 - val_acc: 0.6839\n",
      "Epoch 24/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.4368 - acc: 0.8228 - val_loss: 0.7741 - val_acc: 0.6726\n",
      "Epoch 25/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.4300 - acc: 0.8252 - val_loss: 0.7591 - val_acc: 0.6869\n",
      "Epoch 26/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.4269 - acc: 0.8280 - val_loss: 0.7705 - val_acc: 0.6898\n",
      "Epoch 27/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.4098 - acc: 0.8338 - val_loss: 0.7792 - val_acc: 0.6916\n",
      "Epoch 28/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.4043 - acc: 0.8378 - val_loss: 0.7960 - val_acc: 0.6827\n",
      "Epoch 29/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.3998 - acc: 0.8393 - val_loss: 0.7894 - val_acc: 0.6827\n",
      "Epoch 30/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3926 - acc: 0.8409 - val_loss: 0.7560 - val_acc: 0.6922\n",
      "Epoch 31/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.3915 - acc: 0.8434 - val_loss: 0.7979 - val_acc: 0.6815\n",
      "Epoch 32/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.3833 - acc: 0.8470 - val_loss: 0.7911 - val_acc: 0.6964\n",
      "Epoch 33/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3847 - acc: 0.8458 - val_loss: 0.7828 - val_acc: 0.6910\n",
      "Epoch 34/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.3766 - acc: 0.8478 - val_loss: 0.8104 - val_acc: 0.6904\n",
      "Epoch 35/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3696 - acc: 0.8534 - val_loss: 0.7916 - val_acc: 0.6940\n",
      "Epoch 36/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3669 - acc: 0.8526 - val_loss: 0.7720 - val_acc: 0.7023\n",
      "Epoch 37/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3587 - acc: 0.8564 - val_loss: 0.7935 - val_acc: 0.6964\n",
      "Epoch 38/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.3594 - acc: 0.8560 - val_loss: 0.8159 - val_acc: 0.6881\n",
      "Epoch 39/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3552 - acc: 0.8592 - val_loss: 0.7830 - val_acc: 0.6958\n",
      "Epoch 40/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3470 - acc: 0.8608 - val_loss: 0.8070 - val_acc: 0.6928\n",
      "Epoch 41/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3484 - acc: 0.8610 - val_loss: 0.8131 - val_acc: 0.6892\n",
      "Epoch 42/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3374 - acc: 0.8662 - val_loss: 0.7896 - val_acc: 0.7011\n",
      "Epoch 43/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3308 - acc: 0.8696 - val_loss: 0.7873 - val_acc: 0.7071\n",
      "Epoch 44/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3281 - acc: 0.8699 - val_loss: 0.7981 - val_acc: 0.7029\n",
      "Epoch 45/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3247 - acc: 0.8729 - val_loss: 0.8173 - val_acc: 0.7053\n",
      "Epoch 46/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3254 - acc: 0.8718 - val_loss: 0.7977 - val_acc: 0.6993\n",
      "Epoch 47/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3276 - acc: 0.8710 - val_loss: 0.7943 - val_acc: 0.7017\n",
      "Epoch 48/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3144 - acc: 0.8759 - val_loss: 0.7937 - val_acc: 0.7005\n",
      "Epoch 49/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3219 - acc: 0.8731 - val_loss: 0.8081 - val_acc: 0.6988\n",
      "Epoch 50/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.3123 - acc: 0.8783 - val_loss: 0.8303 - val_acc: 0.7029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3321272b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full run on 50 epochs\n",
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=32, epochs=50, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's save those weights.\n",
    "bn_da_model.save_weights(path+'models/bn_da5_dense256_p05_lr001_conv241_50e.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Unable to open file: name = 'data/testing/models/bn_da5_conv241_50e.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-dd5c96112cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let's load those weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbn_da_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'models/bn_da5_conv241_50e.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eric/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-tnf92dft-build/h5py/_objects.c:2853)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-tnf92dft-build/h5py/_objects.c:2811)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/tmp/pip-tnf92dft-build/h5py/h5f.c:2099)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (Unable to open file: name = 'data/testing/models/bn_da5_conv241_50e.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Let's load those weights.\n",
    "bn_da_model.load_weights(path+'models/bn_da5_dense256_p05_lr001_conv241_50e.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_da_model = Sequential(get_bn_da_layers(p))\n",
    "bn_da_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/50\n",
      "30288/30288 [==============================] - 44s - loss: 1.1863 - acc: 0.4562 - val_loss: 0.9597 - val_acc: 0.5235\n",
      "Epoch 2/50\n",
      "30288/30288 [==============================] - 46s - loss: 0.9717 - acc: 0.5295 - val_loss: 0.9242 - val_acc: 0.5318\n",
      "Epoch 3/50\n",
      "30288/30288 [==============================] - 30s - loss: 0.9373 - acc: 0.5380 - val_loss: 0.8997 - val_acc: 0.5478\n",
      "Epoch 4/50\n",
      "30288/30288 [==============================] - 8s - loss: 0.9160 - acc: 0.5535 - val_loss: 0.8810 - val_acc: 0.5603\n",
      "Epoch 5/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8946 - acc: 0.5642 - val_loss: 0.8609 - val_acc: 0.5716\n",
      "Epoch 6/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8735 - acc: 0.5804 - val_loss: 0.8424 - val_acc: 0.5829\n",
      "Epoch 7/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8580 - acc: 0.5920 - val_loss: 0.8327 - val_acc: 0.5918\n",
      "Epoch 8/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8387 - acc: 0.6016 - val_loss: 0.8238 - val_acc: 0.6102\n",
      "Epoch 9/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8221 - acc: 0.6137 - val_loss: 0.8164 - val_acc: 0.6055\n",
      "Epoch 10/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8111 - acc: 0.6233 - val_loss: 0.8098 - val_acc: 0.6156\n",
      "Epoch 11/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7944 - acc: 0.6333 - val_loss: 0.8029 - val_acc: 0.6162\n",
      "Epoch 12/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7855 - acc: 0.6379 - val_loss: 0.8164 - val_acc: 0.6102\n",
      "Epoch 13/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7824 - acc: 0.6406 - val_loss: 0.7975 - val_acc: 0.6185\n",
      "Epoch 14/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7646 - acc: 0.6510 - val_loss: 0.7843 - val_acc: 0.6310\n",
      "Epoch 15/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7575 - acc: 0.6601 - val_loss: 0.7849 - val_acc: 0.6334\n",
      "Epoch 16/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7482 - acc: 0.6619 - val_loss: 0.7798 - val_acc: 0.6429\n",
      "Epoch 17/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7382 - acc: 0.6676 - val_loss: 0.7850 - val_acc: 0.6364\n",
      "Epoch 18/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7339 - acc: 0.6698 - val_loss: 0.7921 - val_acc: 0.6304\n",
      "Epoch 19/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7307 - acc: 0.6723 - val_loss: 0.7772 - val_acc: 0.6328\n",
      "Epoch 20/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7208 - acc: 0.6807 - val_loss: 0.7698 - val_acc: 0.6494\n",
      "Epoch 21/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7170 - acc: 0.6779 - val_loss: 0.7732 - val_acc: 0.6494\n",
      "Epoch 22/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7036 - acc: 0.6852 - val_loss: 0.7734 - val_acc: 0.6524\n",
      "Epoch 23/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6978 - acc: 0.6917 - val_loss: 0.7826 - val_acc: 0.6447\n",
      "Epoch 24/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6933 - acc: 0.6903 - val_loss: 0.7882 - val_acc: 0.6447\n",
      "Epoch 25/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6890 - acc: 0.6960 - val_loss: 0.7820 - val_acc: 0.6429\n",
      "Epoch 26/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6844 - acc: 0.6987 - val_loss: 0.7768 - val_acc: 0.6465\n",
      "Epoch 27/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6832 - acc: 0.6983 - val_loss: 0.7652 - val_acc: 0.6560\n",
      "Epoch 28/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6800 - acc: 0.7018 - val_loss: 0.7680 - val_acc: 0.6542\n",
      "Epoch 29/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6722 - acc: 0.7092 - val_loss: 0.7734 - val_acc: 0.6578\n",
      "Epoch 30/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6666 - acc: 0.7059 - val_loss: 0.7714 - val_acc: 0.6560\n",
      "Epoch 31/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6634 - acc: 0.7128 - val_loss: 0.7622 - val_acc: 0.6631\n",
      "Epoch 32/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6629 - acc: 0.7104 - val_loss: 0.7507 - val_acc: 0.6655\n",
      "Epoch 33/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6588 - acc: 0.7171 - val_loss: 0.7591 - val_acc: 0.6643\n",
      "Epoch 34/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6436 - acc: 0.7253 - val_loss: 0.7440 - val_acc: 0.6679\n",
      "Epoch 35/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6401 - acc: 0.7229 - val_loss: 0.7561 - val_acc: 0.6655\n",
      "Epoch 36/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6455 - acc: 0.7207 - val_loss: 0.7630 - val_acc: 0.6572\n",
      "Epoch 37/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6423 - acc: 0.7233 - val_loss: 0.7602 - val_acc: 0.6661\n",
      "Epoch 38/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6392 - acc: 0.7231 - val_loss: 0.7520 - val_acc: 0.6625\n",
      "Epoch 39/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6320 - acc: 0.7288 - val_loss: 0.7648 - val_acc: 0.6673\n",
      "Epoch 40/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6285 - acc: 0.7304 - val_loss: 0.7586 - val_acc: 0.6696\n",
      "Epoch 41/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6293 - acc: 0.7314 - val_loss: 0.7530 - val_acc: 0.6720\n",
      "Epoch 42/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6243 - acc: 0.7351 - val_loss: 0.7631 - val_acc: 0.6595\n",
      "Epoch 43/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6204 - acc: 0.7371 - val_loss: 0.7621 - val_acc: 0.6720\n",
      "Epoch 44/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6157 - acc: 0.7360 - val_loss: 0.7642 - val_acc: 0.6756\n",
      "Epoch 45/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6158 - acc: 0.7360 - val_loss: 0.7569 - val_acc: 0.6702\n",
      "Epoch 46/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6149 - acc: 0.7365 - val_loss: 0.7573 - val_acc: 0.6708\n",
      "Epoch 47/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6036 - acc: 0.7437 - val_loss: 0.7669 - val_acc: 0.6679\n",
      "Epoch 48/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6078 - acc: 0.7414 - val_loss: 0.7853 - val_acc: 0.6673\n",
      "Epoch 49/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6101 - acc: 0.7405 - val_loss: 0.7460 - val_acc: 0.6780\n",
      "Epoch 50/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6026 - acc: 0.7453 - val_loss: 0.7468 - val_acc: 0.6827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe32283a7b8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full run on 50 epochs\n",
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=32, epochs=50, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's save those weights.\n",
    "bn_da_model.save_weights(path+'models/bn_da5_dense3_64_p06_lr001_conv241_50e.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_da_model = Sequential(get_bn_da_layers(p))\n",
    "bn_da_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/50\n",
      "30288/30288 [==============================] - 6s - loss: 1.0030 - acc: 0.5225 - val_loss: 0.8518 - val_acc: 0.5888\n",
      "Epoch 2/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.8043 - acc: 0.6230 - val_loss: 0.8163 - val_acc: 0.6245\n",
      "Epoch 3/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.7070 - acc: 0.6823 - val_loss: 0.8028 - val_acc: 0.6536\n",
      "Epoch 4/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.6250 - acc: 0.7254 - val_loss: 0.7909 - val_acc: 0.6524\n",
      "Epoch 5/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.5557 - acc: 0.7647 - val_loss: 0.7757 - val_acc: 0.6655\n",
      "Epoch 6/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.5020 - acc: 0.7854 - val_loss: 0.8146 - val_acc: 0.6714\n",
      "Epoch 7/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.4432 - acc: 0.8177 - val_loss: 0.8061 - val_acc: 0.6791\n",
      "Epoch 8/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.3997 - acc: 0.8385 - val_loss: 0.8838 - val_acc: 0.6791\n",
      "Epoch 9/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.3673 - acc: 0.8520 - val_loss: 0.8983 - val_acc: 0.6839\n",
      "Epoch 10/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.3389 - acc: 0.8657 - val_loss: 0.9156 - val_acc: 0.6815\n",
      "Epoch 11/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.3130 - acc: 0.8755 - val_loss: 0.9115 - val_acc: 0.6750\n",
      "Epoch 12/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.2933 - acc: 0.8868 - val_loss: 0.9575 - val_acc: 0.6714\n",
      "Epoch 13/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.2692 - acc: 0.8955 - val_loss: 0.9735 - val_acc: 0.6898\n",
      "Epoch 14/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.2504 - acc: 0.9031 - val_loss: 1.0175 - val_acc: 0.6684\n",
      "Epoch 15/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.2429 - acc: 0.9076 - val_loss: 1.0146 - val_acc: 0.6768\n",
      "Epoch 16/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.2322 - acc: 0.9122 - val_loss: 1.0079 - val_acc: 0.6780\n",
      "Epoch 17/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.2271 - acc: 0.9160 - val_loss: 1.0426 - val_acc: 0.6898\n",
      "Epoch 18/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.2102 - acc: 0.9200 - val_loss: 1.0776 - val_acc: 0.6851\n",
      "Epoch 19/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.2098 - acc: 0.9203 - val_loss: 1.0032 - val_acc: 0.6940\n",
      "Epoch 20/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1968 - acc: 0.9267 - val_loss: 1.0348 - val_acc: 0.6845\n",
      "Epoch 21/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.1874 - acc: 0.9287 - val_loss: 1.0877 - val_acc: 0.6833\n",
      "Epoch 22/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1846 - acc: 0.9296 - val_loss: 1.0602 - val_acc: 0.6833\n",
      "Epoch 23/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.1803 - acc: 0.9323 - val_loss: 1.0861 - val_acc: 0.6881\n",
      "Epoch 24/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1713 - acc: 0.9363 - val_loss: 1.0936 - val_acc: 0.6958\n",
      "Epoch 25/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1709 - acc: 0.9366 - val_loss: 1.0962 - val_acc: 0.6839\n",
      "Epoch 26/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.1630 - acc: 0.9398 - val_loss: 1.1706 - val_acc: 0.6910\n",
      "Epoch 27/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1549 - acc: 0.9410 - val_loss: 1.1709 - val_acc: 0.6845\n",
      "Epoch 28/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1517 - acc: 0.9430 - val_loss: 1.1538 - val_acc: 0.6928\n",
      "Epoch 29/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1462 - acc: 0.9462 - val_loss: 1.1309 - val_acc: 0.6988\n",
      "Epoch 30/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1488 - acc: 0.9452 - val_loss: 1.1245 - val_acc: 0.6993\n",
      "Epoch 31/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1441 - acc: 0.9480 - val_loss: 1.1814 - val_acc: 0.6993\n",
      "Epoch 32/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1384 - acc: 0.9492 - val_loss: 1.1234 - val_acc: 0.6982\n",
      "Epoch 33/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1371 - acc: 0.9491 - val_loss: 1.1124 - val_acc: 0.7035\n",
      "Epoch 34/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1331 - acc: 0.9516 - val_loss: 1.1679 - val_acc: 0.7011\n",
      "Epoch 35/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1248 - acc: 0.9546 - val_loss: 1.2345 - val_acc: 0.7005\n",
      "Epoch 36/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1243 - acc: 0.9536 - val_loss: 1.2450 - val_acc: 0.6946\n",
      "Epoch 37/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1244 - acc: 0.9552 - val_loss: 1.1885 - val_acc: 0.7035\n",
      "Epoch 38/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1211 - acc: 0.9558 - val_loss: 1.1772 - val_acc: 0.7059\n",
      "Epoch 39/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1254 - acc: 0.9555 - val_loss: 1.1921 - val_acc: 0.6928\n",
      "Epoch 40/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1202 - acc: 0.9561 - val_loss: 1.3131 - val_acc: 0.7041\n",
      "Epoch 41/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1198 - acc: 0.9567 - val_loss: 1.1997 - val_acc: 0.7023\n",
      "Epoch 42/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1121 - acc: 0.9597 - val_loss: 1.2402 - val_acc: 0.6940\n",
      "Epoch 43/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1174 - acc: 0.9591 - val_loss: 1.2488 - val_acc: 0.6934\n",
      "Epoch 44/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1166 - acc: 0.9578 - val_loss: 1.2264 - val_acc: 0.6934\n",
      "Epoch 45/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.1126 - acc: 0.9595 - val_loss: 1.2504 - val_acc: 0.6904\n",
      "Epoch 46/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1110 - acc: 0.9600 - val_loss: 1.2281 - val_acc: 0.6982\n",
      "Epoch 47/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1076 - acc: 0.9608 - val_loss: 1.2195 - val_acc: 0.7029\n",
      "Epoch 48/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.1047 - acc: 0.9633 - val_loss: 1.2983 - val_acc: 0.6928\n",
      "Epoch 49/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.1070 - acc: 0.9613 - val_loss: 1.2037 - val_acc: 0.6999\n",
      "Epoch 50/50\n",
      "30288/30288 [==============================] - 5s - loss: 0.1000 - acc: 0.9653 - val_loss: 1.2497 - val_acc: 0.7005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe32865ae80>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full run on 50 epochs\n",
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=32, epochs=50, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's save those weights.\n",
    "bn_da_model.save_weights(path+'models/bn_da5_dense256_p03_lr001_conv241_50e.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_da_model = Sequential(get_bn_da_layers(p))\n",
    "bn_da_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/50\n",
      "30288/30288 [==============================] - 17s - loss: 1.2045 - acc: 0.4648 - val_loss: 0.9332 - val_acc: 0.5264\n",
      "Epoch 2/50\n",
      "30288/30288 [==============================] - 17s - loss: 0.9545 - acc: 0.5337 - val_loss: 0.9009 - val_acc: 0.5466\n",
      "Epoch 3/50\n",
      "30288/30288 [==============================] - 16s - loss: 0.9250 - acc: 0.5491 - val_loss: 0.8807 - val_acc: 0.5567\n",
      "Epoch 4/50\n",
      "30288/30288 [==============================] - 13s - loss: 0.9040 - acc: 0.5587 - val_loss: 0.8664 - val_acc: 0.5769\n",
      "Epoch 5/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8870 - acc: 0.5720 - val_loss: 0.8526 - val_acc: 0.5847\n",
      "Epoch 6/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8669 - acc: 0.5865 - val_loss: 0.8476 - val_acc: 0.5722\n",
      "Epoch 7/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8527 - acc: 0.5925 - val_loss: 0.8411 - val_acc: 0.5740\n",
      "Epoch 8/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8437 - acc: 0.6024 - val_loss: 0.8315 - val_acc: 0.5882\n",
      "Epoch 9/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8348 - acc: 0.6055 - val_loss: 0.8278 - val_acc: 0.6061\n",
      "Epoch 10/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8286 - acc: 0.6069 - val_loss: 0.8166 - val_acc: 0.6108\n",
      "Epoch 11/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8201 - acc: 0.6141 - val_loss: 0.8186 - val_acc: 0.6078\n",
      "Epoch 12/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8077 - acc: 0.6223 - val_loss: 0.8169 - val_acc: 0.6084\n",
      "Epoch 13/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8032 - acc: 0.6289 - val_loss: 0.8125 - val_acc: 0.6150\n",
      "Epoch 14/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7954 - acc: 0.6301 - val_loss: 0.8105 - val_acc: 0.6185\n",
      "Epoch 15/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7903 - acc: 0.6352 - val_loss: 0.8083 - val_acc: 0.6263\n",
      "Epoch 16/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7790 - acc: 0.6421 - val_loss: 0.8072 - val_acc: 0.6227\n",
      "Epoch 17/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7720 - acc: 0.6468 - val_loss: 0.7970 - val_acc: 0.6257\n",
      "Epoch 18/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7644 - acc: 0.6516 - val_loss: 0.7860 - val_acc: 0.6370\n",
      "Epoch 19/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7646 - acc: 0.6499 - val_loss: 0.8033 - val_acc: 0.6257\n",
      "Epoch 20/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7559 - acc: 0.6515 - val_loss: 0.7893 - val_acc: 0.6364\n",
      "Epoch 21/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7483 - acc: 0.6571 - val_loss: 0.7865 - val_acc: 0.6346\n",
      "Epoch 22/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7487 - acc: 0.6600 - val_loss: 0.7790 - val_acc: 0.6435\n",
      "Epoch 23/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7372 - acc: 0.6631 - val_loss: 0.7789 - val_acc: 0.6441\n",
      "Epoch 24/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7358 - acc: 0.6678 - val_loss: 0.7795 - val_acc: 0.6405\n",
      "Epoch 25/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7319 - acc: 0.6729 - val_loss: 0.7823 - val_acc: 0.6435\n",
      "Epoch 26/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7249 - acc: 0.6703 - val_loss: 0.7700 - val_acc: 0.6494\n",
      "Epoch 27/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7229 - acc: 0.6718 - val_loss: 0.7729 - val_acc: 0.6459\n",
      "Epoch 28/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7251 - acc: 0.6714 - val_loss: 0.7732 - val_acc: 0.6453\n",
      "Epoch 29/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7134 - acc: 0.6799 - val_loss: 0.7770 - val_acc: 0.6453\n",
      "Epoch 30/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7123 - acc: 0.6814 - val_loss: 0.7702 - val_acc: 0.6453\n",
      "Epoch 31/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7079 - acc: 0.6852 - val_loss: 0.7651 - val_acc: 0.6530\n",
      "Epoch 32/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7080 - acc: 0.6828 - val_loss: 0.7680 - val_acc: 0.6488\n",
      "Epoch 33/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.7003 - acc: 0.6857 - val_loss: 0.7685 - val_acc: 0.6471\n",
      "Epoch 34/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6994 - acc: 0.6866 - val_loss: 0.7692 - val_acc: 0.6482\n",
      "Epoch 35/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6941 - acc: 0.6944 - val_loss: 0.7747 - val_acc: 0.6554\n",
      "Epoch 36/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6937 - acc: 0.6934 - val_loss: 0.7482 - val_acc: 0.6554\n",
      "Epoch 37/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6874 - acc: 0.6947 - val_loss: 0.7630 - val_acc: 0.6494\n",
      "Epoch 38/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6785 - acc: 0.7004 - val_loss: 0.7545 - val_acc: 0.6554\n",
      "Epoch 39/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6864 - acc: 0.6987 - val_loss: 0.7567 - val_acc: 0.6619\n",
      "Epoch 40/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6749 - acc: 0.6994 - val_loss: 0.7553 - val_acc: 0.6595\n",
      "Epoch 41/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6648 - acc: 0.7062 - val_loss: 0.7531 - val_acc: 0.6554\n",
      "Epoch 42/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6726 - acc: 0.7030 - val_loss: 0.7539 - val_acc: 0.6601\n",
      "Epoch 43/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6680 - acc: 0.7082 - val_loss: 0.7481 - val_acc: 0.6625\n",
      "Epoch 44/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6628 - acc: 0.7071 - val_loss: 0.7497 - val_acc: 0.6613\n",
      "Epoch 45/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6643 - acc: 0.7079 - val_loss: 0.7448 - val_acc: 0.6578\n",
      "Epoch 46/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6655 - acc: 0.7068 - val_loss: 0.7436 - val_acc: 0.6637\n",
      "Epoch 47/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6577 - acc: 0.7119 - val_loss: 0.7554 - val_acc: 0.6595\n",
      "Epoch 48/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6579 - acc: 0.7129 - val_loss: 0.7339 - val_acc: 0.6726\n",
      "Epoch 49/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6483 - acc: 0.7164 - val_loss: 0.7364 - val_acc: 0.6673\n",
      "Epoch 50/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.6568 - acc: 0.7125 - val_loss: 0.7451 - val_acc: 0.6560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe326f3ea20>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full run on 50 epochs\n",
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=32, epochs=50, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's save those weights.\n",
    "bn_da_model.save_weights(path+'models/bn_da5_dense256_p07_lr001_conv241_50e.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_da_model = Sequential(get_bn_da_layers(p))\n",
    "bn_da_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30288 samples, validate on 1683 samples\n",
      "Epoch 1/50\n",
      "30288/30288 [==============================] - 14s - loss: 1.2882 - acc: 0.4573 - val_loss: 0.9740 - val_acc: 0.5294\n",
      "Epoch 2/50\n",
      "30288/30288 [==============================] - 11s - loss: 0.9869 - acc: 0.5267 - val_loss: 0.9408 - val_acc: 0.5354\n",
      "Epoch 3/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.9664 - acc: 0.5288 - val_loss: 0.9202 - val_acc: 0.5371\n",
      "Epoch 4/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.9522 - acc: 0.5414 - val_loss: 0.9140 - val_acc: 0.5348\n",
      "Epoch 5/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.9457 - acc: 0.5381 - val_loss: 0.9000 - val_acc: 0.5490\n",
      "Epoch 6/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.9318 - acc: 0.5427 - val_loss: 0.8925 - val_acc: 0.5472\n",
      "Epoch 7/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.9260 - acc: 0.5477 - val_loss: 0.8866 - val_acc: 0.5496\n",
      "Epoch 8/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.9168 - acc: 0.5529 - val_loss: 0.8787 - val_acc: 0.5567\n",
      "Epoch 9/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.9116 - acc: 0.5559 - val_loss: 0.8813 - val_acc: 0.5573\n",
      "Epoch 10/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.9034 - acc: 0.5605 - val_loss: 0.8697 - val_acc: 0.5728\n",
      "Epoch 11/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8975 - acc: 0.5637 - val_loss: 0.8702 - val_acc: 0.5710\n",
      "Epoch 12/50\n",
      "30288/30288 [==============================] - 8s - loss: 0.8918 - acc: 0.5690 - val_loss: 0.8634 - val_acc: 0.5633\n",
      "Epoch 13/50\n",
      "30288/30288 [==============================] - 7s - loss: 0.8857 - acc: 0.5712 - val_loss: 0.8555 - val_acc: 0.5811\n",
      "Epoch 14/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8837 - acc: 0.5731 - val_loss: 0.8513 - val_acc: 0.5823\n",
      "Epoch 15/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8795 - acc: 0.5756 - val_loss: 0.8478 - val_acc: 0.5817\n",
      "Epoch 16/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8714 - acc: 0.5820 - val_loss: 0.8446 - val_acc: 0.5859\n",
      "Epoch 17/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8715 - acc: 0.5792 - val_loss: 0.8467 - val_acc: 0.5787\n",
      "Epoch 18/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8652 - acc: 0.5818 - val_loss: 0.8417 - val_acc: 0.5853\n",
      "Epoch 19/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8649 - acc: 0.5839 - val_loss: 0.8434 - val_acc: 0.5912\n",
      "Epoch 20/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8618 - acc: 0.5872 - val_loss: 0.8403 - val_acc: 0.5823\n",
      "Epoch 21/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8532 - acc: 0.5894 - val_loss: 0.8371 - val_acc: 0.5948\n",
      "Epoch 22/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8518 - acc: 0.5974 - val_loss: 0.8325 - val_acc: 0.5942\n",
      "Epoch 23/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8509 - acc: 0.5942 - val_loss: 0.8304 - val_acc: 0.5989\n",
      "Epoch 24/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8450 - acc: 0.5963 - val_loss: 0.8304 - val_acc: 0.5966\n",
      "Epoch 25/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8440 - acc: 0.6001 - val_loss: 0.8280 - val_acc: 0.5966\n",
      "Epoch 26/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8449 - acc: 0.6030 - val_loss: 0.8266 - val_acc: 0.6025\n",
      "Epoch 27/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8398 - acc: 0.6041 - val_loss: 0.8251 - val_acc: 0.6007\n",
      "Epoch 28/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8393 - acc: 0.6025 - val_loss: 0.8252 - val_acc: 0.6043\n",
      "Epoch 29/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8375 - acc: 0.6036 - val_loss: 0.8239 - val_acc: 0.6013\n",
      "Epoch 30/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8338 - acc: 0.6060 - val_loss: 0.8253 - val_acc: 0.6031\n",
      "Epoch 31/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8347 - acc: 0.6090 - val_loss: 0.8241 - val_acc: 0.6037\n",
      "Epoch 32/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8327 - acc: 0.6076 - val_loss: 0.8203 - val_acc: 0.6067\n",
      "Epoch 33/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8273 - acc: 0.6092 - val_loss: 0.8169 - val_acc: 0.6049\n",
      "Epoch 34/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8319 - acc: 0.6079 - val_loss: 0.8175 - val_acc: 0.6096\n",
      "Epoch 35/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8277 - acc: 0.6106 - val_loss: 0.8179 - val_acc: 0.6084\n",
      "Epoch 36/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8259 - acc: 0.6113 - val_loss: 0.8167 - val_acc: 0.6055\n",
      "Epoch 37/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8219 - acc: 0.6139 - val_loss: 0.8163 - val_acc: 0.6108\n",
      "Epoch 38/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8193 - acc: 0.6127 - val_loss: 0.8217 - val_acc: 0.6013\n",
      "Epoch 39/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8242 - acc: 0.6150 - val_loss: 0.8156 - val_acc: 0.6156\n",
      "Epoch 40/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8198 - acc: 0.6168 - val_loss: 0.8149 - val_acc: 0.6102\n",
      "Epoch 41/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8196 - acc: 0.6159 - val_loss: 0.8177 - val_acc: 0.6055\n",
      "Epoch 42/50\n",
      "30288/30288 [==============================] - 8s - loss: 0.8189 - acc: 0.6172 - val_loss: 0.8164 - val_acc: 0.6078\n",
      "Epoch 43/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8161 - acc: 0.6160 - val_loss: 0.8161 - val_acc: 0.6072\n",
      "Epoch 44/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8139 - acc: 0.6209 - val_loss: 0.8135 - val_acc: 0.6072\n",
      "Epoch 45/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8118 - acc: 0.6234 - val_loss: 0.8103 - val_acc: 0.6108\n",
      "Epoch 46/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8105 - acc: 0.6200 - val_loss: 0.8102 - val_acc: 0.6061\n",
      "Epoch 47/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8147 - acc: 0.6181 - val_loss: 0.8105 - val_acc: 0.6120\n",
      "Epoch 48/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8102 - acc: 0.6225 - val_loss: 0.8069 - val_acc: 0.6179\n",
      "Epoch 49/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8045 - acc: 0.6246 - val_loss: 0.8060 - val_acc: 0.6138\n",
      "Epoch 50/50\n",
      "30288/30288 [==============================] - 6s - loss: 0.8049 - acc: 0.6267 - val_loss: 0.8073 - val_acc: 0.6173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3255cc550>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full run on 50 epochs\n",
    "bn_da_model.fit(da_conv_feat_update, da_trn_labels, batch_size=32, epochs=50, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's save those weights.\n",
    "bn_da_model.save_weights(path+'models/bn_da5_dense256_p08_lr001_conv241_50e.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions\n",
    "\n",
    "Don't forget to add clipping for Kaggle submissions as it's very important to get the best cross_entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_preds = bn_da_model.predict(conv_val_feat, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74608827417631163"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(keras.metrics.categorical_crossentropy(val_labels, do_clip(val_preds, 0.93)).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = load_array(path+'results/bn_conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_da_model.save_weights(path+'models/bn_da5_dense256_p06_lr001_conv241_50e.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = bn_da_model.predict(conv_test_feat, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds,0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = path+'results/subm_24_bn_da_vgg_clip093_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0.108437</td>\n",
       "      <td>0.195085</td>\n",
       "      <td>0.696478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0.051419</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>0.921474</td>\n",
       "      <td>0.047782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.895548</td>\n",
       "      <td>0.085818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>0.037839</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.009036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name    Type_1    Type_2    Type_3\n",
       "0      0.jpg  0.108437  0.195085  0.696478\n",
       "1      1.jpg  0.051419  0.930000  0.007778\n",
       "2     10.jpg  0.030744  0.921474  0.047782\n",
       "3    100.jpg  0.018633  0.895548  0.085818\n",
       "4  10000.jpg  0.037839  0.930000  0.009036"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'image_name', [a[8:] for a in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/testing/results/subm_24_bn_da_vgg_clip093_1.csv' target='_blank'>data/testing/results/subm_24_bn_da_vgg_clip093_1.csv</a><br>"
      ],
      "text/plain": [
       "/media/eric/SSD500/fastai/deeplearning1/nbs/MobileODT/data/testing/results/subm_24_bn_da_vgg_clip093_1.csv"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
